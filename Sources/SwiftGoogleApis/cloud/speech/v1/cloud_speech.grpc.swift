//
// DO NOT EDIT.
//
// Generated by the protocol buffer compiler.
// Source: google/cloud/speech/v1/cloud_speech.proto
//

//
// Copyright 2018, gRPC Authors All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
import GRPC
import NIO
import NIOConcurrencyHelpers
import SwiftProtobuf


/// Service that implements Google Cloud Speech API.
///
/// Usage: instantiate `Google_Cloud_Speech_V1_SpeechClient`, then call methods of this protocol to make API calls.
internal protocol Google_Cloud_Speech_V1_SpeechClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? { get }

  func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>

  func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>

  func streamingRecognize(
    callOptions: CallOptions?,
    handler: @escaping (Google_Cloud_Speech_V1_StreamingRecognizeResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>
}

extension Google_Cloud_Speech_V1_SpeechClientProtocol {
  internal var serviceName: String {
    return "google.cloud.speech.v1.Speech"
  }

  /// Performs synchronous speech recognition: receive results after all audio
  /// has been sent and processed.
  ///
  /// - Parameters:
  ///   - request: Request to send to Recognize.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  internal func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse> {
    return self.makeUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  /// Performs asynchronous speech recognition: receive results via the
  /// google.longrunning.Operations interface. Returns either an
  /// `Operation.error` or an `Operation.response` which contains
  /// a `LongRunningRecognizeResponse` message.
  ///
  /// - Parameters:
  ///   - request: Request to send to LongRunningRecognize.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  internal func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation> {
    return self.makeUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  /// Performs bidirectional streaming speech recognition: receive results while
  /// sending audio. This method is only available via the gRPC API (not REST).
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  ///   - handler: A closure called when each response is received from the server.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata and status.
  internal func streamingRecognize(
    callOptions: CallOptions? = nil,
    handler: @escaping (Google_Cloud_Speech_V1_StreamingRecognizeResponse) -> Void
  ) -> BidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse> {
    return self.makeBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? [],
      handler: handler
    )
  }
}

#if compiler(>=5.6)
@available(*, deprecated)
extension Google_Cloud_Speech_V1_SpeechClient: @unchecked Sendable {}
#endif // compiler(>=5.6)

@available(*, deprecated, renamed: "Google_Cloud_Speech_V1_SpeechNIOClient")
internal final class Google_Cloud_Speech_V1_SpeechClient: Google_Cloud_Speech_V1_SpeechClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?
  internal let channel: GRPCChannel
  internal var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  internal var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the google.cloud.speech.v1.Speech service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  internal init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

internal struct Google_Cloud_Speech_V1_SpeechNIOClient: Google_Cloud_Speech_V1_SpeechClientProtocol {
  internal var channel: GRPCChannel
  internal var defaultCallOptions: CallOptions
  internal var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?

  /// Creates a client for the google.cloud.speech.v1.Speech service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  internal init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#if compiler(>=5.6)
/// Service that implements Google Cloud Speech API.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
internal protocol Google_Cloud_Speech_V1_SpeechAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? { get }

  func makeRecognizeCall(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>

  func makeLongRunningRecognizeCall(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>

  func makeStreamingRecognizeCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncBidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  internal static var serviceDescriptor: GRPCServiceDescriptor {
    return Google_Cloud_Speech_V1_SpeechClientMetadata.serviceDescriptor
  }

  internal var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? {
    return nil
  }

  internal func makeRecognizeCall(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse> {
    return self.makeAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  internal func makeLongRunningRecognizeCall(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation> {
    return self.makeAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  internal func makeStreamingRecognizeCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncBidirectionalStreamingCall<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse> {
    return self.makeAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  internal func recognize(
    _ request: Google_Cloud_Speech_V1_RecognizeRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Google_Cloud_Speech_V1_RecognizeResponse {
    return try await self.performAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeRecognizeInterceptors() ?? []
    )
  }

  internal func longRunningRecognize(
    _ request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Google_Longrunning_Operation {
    return try await self.performAsyncUnaryCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? []
    )
  }

  internal func streamingRecognize<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Google_Cloud_Speech_V1_StreamingRecognizeResponse> where RequestStream: Sequence, RequestStream.Element == Google_Cloud_Speech_V1_StreamingRecognizeRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }

  internal func streamingRecognize<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncResponseStream<Google_Cloud_Speech_V1_StreamingRecognizeResponse> where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Google_Cloud_Speech_V1_StreamingRecognizeRequest {
    return self.performAsyncBidirectionalStreamingCall(
      path: Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
internal struct Google_Cloud_Speech_V1_SpeechAsyncClient: Google_Cloud_Speech_V1_SpeechAsyncClientProtocol {
  internal var channel: GRPCChannel
  internal var defaultCallOptions: CallOptions
  internal var interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol?

  internal init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

#endif // compiler(>=5.6)

internal protocol Google_Cloud_Speech_V1_SpeechClientInterceptorFactoryProtocol: GRPCSendable {

  /// - Returns: Interceptors to use when invoking 'recognize'.
  func makeRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>]

  /// - Returns: Interceptors to use when invoking 'longRunningRecognize'.
  func makeLongRunningRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>]

  /// - Returns: Interceptors to use when invoking 'streamingRecognize'.
  func makeStreamingRecognizeInterceptors() -> [ClientInterceptor<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>]
}

internal enum Google_Cloud_Speech_V1_SpeechClientMetadata {
  internal static let serviceDescriptor = GRPCServiceDescriptor(
    name: "Speech",
    fullName: "google.cloud.speech.v1.Speech",
    methods: [
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.recognize,
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.longRunningRecognize,
      Google_Cloud_Speech_V1_SpeechClientMetadata.Methods.streamingRecognize,
    ]
  )

  internal enum Methods {
    internal static let recognize = GRPCMethodDescriptor(
      name: "Recognize",
      path: "/google.cloud.speech.v1.Speech/Recognize",
      type: GRPCCallType.unary
    )

    internal static let longRunningRecognize = GRPCMethodDescriptor(
      name: "LongRunningRecognize",
      path: "/google.cloud.speech.v1.Speech/LongRunningRecognize",
      type: GRPCCallType.unary
    )

    internal static let streamingRecognize = GRPCMethodDescriptor(
      name: "StreamingRecognize",
      path: "/google.cloud.speech.v1.Speech/StreamingRecognize",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}

/// Service that implements Google Cloud Speech API.
///
/// To build a server, implement a class that conforms to this protocol.
internal protocol Google_Cloud_Speech_V1_SpeechProvider: CallHandlerProvider {
  var interceptors: Google_Cloud_Speech_V1_SpeechServerInterceptorFactoryProtocol? { get }

  /// Performs synchronous speech recognition: receive results after all audio
  /// has been sent and processed.
  func recognize(request: Google_Cloud_Speech_V1_RecognizeRequest, context: StatusOnlyCallContext) -> EventLoopFuture<Google_Cloud_Speech_V1_RecognizeResponse>

  /// Performs asynchronous speech recognition: receive results via the
  /// google.longrunning.Operations interface. Returns either an
  /// `Operation.error` or an `Operation.response` which contains
  /// a `LongRunningRecognizeResponse` message.
  func longRunningRecognize(request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest, context: StatusOnlyCallContext) -> EventLoopFuture<Google_Longrunning_Operation>

  /// Performs bidirectional streaming speech recognition: receive results while
  /// sending audio. This method is only available via the gRPC API (not REST).
  func streamingRecognize(context: StreamingResponseCallContext<Google_Cloud_Speech_V1_StreamingRecognizeResponse>) -> EventLoopFuture<(StreamEvent<Google_Cloud_Speech_V1_StreamingRecognizeRequest>) -> Void>
}

extension Google_Cloud_Speech_V1_SpeechProvider {
  internal var serviceName: Substring {
    return Google_Cloud_Speech_V1_SpeechServerMetadata.serviceDescriptor.fullName[...]
  }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  internal func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "Recognize":
      return UnaryServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_RecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Cloud_Speech_V1_RecognizeResponse>(),
        interceptors: self.interceptors?.makeRecognizeInterceptors() ?? [],
        userFunction: self.recognize(request:context:)
      )

    case "LongRunningRecognize":
      return UnaryServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_LongRunningRecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Longrunning_Operation>(),
        interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? [],
        userFunction: self.longRunningRecognize(request:context:)
      )

    case "StreamingRecognize":
      return BidirectionalStreamingServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_StreamingRecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Cloud_Speech_V1_StreamingRecognizeResponse>(),
        interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? [],
        observerFactory: self.streamingRecognize(context:)
      )

    default:
      return nil
    }
  }
}

#if compiler(>=5.6)

/// Service that implements Google Cloud Speech API.
///
/// To implement a server, implement an object which conforms to this protocol.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
internal protocol Google_Cloud_Speech_V1_SpeechAsyncProvider: CallHandlerProvider {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Google_Cloud_Speech_V1_SpeechServerInterceptorFactoryProtocol? { get }

  /// Performs synchronous speech recognition: receive results after all audio
  /// has been sent and processed.
  @Sendable func recognize(
    request: Google_Cloud_Speech_V1_RecognizeRequest,
    context: GRPCAsyncServerCallContext
  ) async throws -> Google_Cloud_Speech_V1_RecognizeResponse

  /// Performs asynchronous speech recognition: receive results via the
  /// google.longrunning.Operations interface. Returns either an
  /// `Operation.error` or an `Operation.response` which contains
  /// a `LongRunningRecognizeResponse` message.
  @Sendable func longRunningRecognize(
    request: Google_Cloud_Speech_V1_LongRunningRecognizeRequest,
    context: GRPCAsyncServerCallContext
  ) async throws -> Google_Longrunning_Operation

  /// Performs bidirectional streaming speech recognition: receive results while
  /// sending audio. This method is only available via the gRPC API (not REST).
  @Sendable func streamingRecognize(
    requestStream: GRPCAsyncRequestStream<Google_Cloud_Speech_V1_StreamingRecognizeRequest>,
    responseStream: GRPCAsyncResponseStreamWriter<Google_Cloud_Speech_V1_StreamingRecognizeResponse>,
    context: GRPCAsyncServerCallContext
  ) async throws
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Google_Cloud_Speech_V1_SpeechAsyncProvider {
  internal static var serviceDescriptor: GRPCServiceDescriptor {
    return Google_Cloud_Speech_V1_SpeechServerMetadata.serviceDescriptor
  }

  internal var serviceName: Substring {
    return Google_Cloud_Speech_V1_SpeechServerMetadata.serviceDescriptor.fullName[...]
  }

  internal var interceptors: Google_Cloud_Speech_V1_SpeechServerInterceptorFactoryProtocol? {
    return nil
  }

  internal func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "Recognize":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_RecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Cloud_Speech_V1_RecognizeResponse>(),
        interceptors: self.interceptors?.makeRecognizeInterceptors() ?? [],
        wrapping: self.recognize(request:context:)
      )

    case "LongRunningRecognize":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_LongRunningRecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Longrunning_Operation>(),
        interceptors: self.interceptors?.makeLongRunningRecognizeInterceptors() ?? [],
        wrapping: self.longRunningRecognize(request:context:)
      )

    case "StreamingRecognize":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Google_Cloud_Speech_V1_StreamingRecognizeRequest>(),
        responseSerializer: ProtobufSerializer<Google_Cloud_Speech_V1_StreamingRecognizeResponse>(),
        interceptors: self.interceptors?.makeStreamingRecognizeInterceptors() ?? [],
        wrapping: self.streamingRecognize(requestStream:responseStream:context:)
      )

    default:
      return nil
    }
  }
}

#endif // compiler(>=5.6)

internal protocol Google_Cloud_Speech_V1_SpeechServerInterceptorFactoryProtocol {

  /// - Returns: Interceptors to use when handling 'recognize'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeRecognizeInterceptors() -> [ServerInterceptor<Google_Cloud_Speech_V1_RecognizeRequest, Google_Cloud_Speech_V1_RecognizeResponse>]

  /// - Returns: Interceptors to use when handling 'longRunningRecognize'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeLongRunningRecognizeInterceptors() -> [ServerInterceptor<Google_Cloud_Speech_V1_LongRunningRecognizeRequest, Google_Longrunning_Operation>]

  /// - Returns: Interceptors to use when handling 'streamingRecognize'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeStreamingRecognizeInterceptors() -> [ServerInterceptor<Google_Cloud_Speech_V1_StreamingRecognizeRequest, Google_Cloud_Speech_V1_StreamingRecognizeResponse>]
}

internal enum Google_Cloud_Speech_V1_SpeechServerMetadata {
  internal static let serviceDescriptor = GRPCServiceDescriptor(
    name: "Speech",
    fullName: "google.cloud.speech.v1.Speech",
    methods: [
      Google_Cloud_Speech_V1_SpeechServerMetadata.Methods.recognize,
      Google_Cloud_Speech_V1_SpeechServerMetadata.Methods.longRunningRecognize,
      Google_Cloud_Speech_V1_SpeechServerMetadata.Methods.streamingRecognize,
    ]
  )

  internal enum Methods {
    internal static let recognize = GRPCMethodDescriptor(
      name: "Recognize",
      path: "/google.cloud.speech.v1.Speech/Recognize",
      type: GRPCCallType.unary
    )

    internal static let longRunningRecognize = GRPCMethodDescriptor(
      name: "LongRunningRecognize",
      path: "/google.cloud.speech.v1.Speech/LongRunningRecognize",
      type: GRPCCallType.unary
    )

    internal static let streamingRecognize = GRPCMethodDescriptor(
      name: "StreamingRecognize",
      path: "/google.cloud.speech.v1.Speech/StreamingRecognize",
      type: GRPCCallType.bidirectionalStreaming
    )
  }
}
