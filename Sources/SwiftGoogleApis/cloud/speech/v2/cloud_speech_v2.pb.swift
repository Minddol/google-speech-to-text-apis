// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: google/cloud/speech/v2/cloud_speech.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Request message for the
/// [CreateRecognizer][google.cloud.speech.v2.Speech.CreateRecognizer] method.
public struct Google_Cloud_Speech_V2_CreateRecognizerRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The Recognizer to create.
  public var recognizer: Google_Cloud_Speech_V2_Recognizer {
    get {return _recognizer ?? Google_Cloud_Speech_V2_Recognizer()}
    set {_recognizer = newValue}
  }
  /// Returns true if `recognizer` has been explicitly set.
  public var hasRecognizer: Bool {return self._recognizer != nil}
  /// Clears the value of `recognizer`. Subsequent reads from it will return its default value.
  public mutating func clearRecognizer() {self._recognizer = nil}

  /// If set, validate the request and preview the Recognizer, but do not
  /// actually create it.
  public var validateOnly: Bool = false

  /// The ID to use for the Recognizer, which will become the final component of
  /// the Recognizer's resource name.
  ///
  /// This value should be 4-63 characters, and valid characters
  /// are /[a-z][0-9]-/.
  public var recognizerID: String = String()

  /// Required. The project and location where this Recognizer will be created.
  /// The expected format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _recognizer: Google_Cloud_Speech_V2_Recognizer? = nil
}

/// Represents the metadata of a long-running operation.
public struct Google_Cloud_Speech_V2_OperationMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The time the operation was created.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return self._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {self._createTime = nil}

  /// The time the operation was last updated.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return self._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {self._updateTime = nil}

  /// The resource path for the target of the operation.
  public var resource: String = String()

  /// The method that triggered the operation.
  public var method: String = String()

  /// The [KMS key
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
  /// the content of the Operation is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
  public var kmsKeyName: String = String()

  /// The [KMS key version
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
  /// with which content of the Operation is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
  public var kmsKeyVersionName: String = String()

  /// The request that spawned the Operation.
  public var request: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Request? = nil

  /// The BatchRecognizeRequest that spawned the Operation.
  public var batchRecognizeRequest: Google_Cloud_Speech_V2_BatchRecognizeRequest {
    get {
      if case .batchRecognizeRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_BatchRecognizeRequest()
    }
    set {request = .batchRecognizeRequest(newValue)}
  }

  /// The CreateRecognizerRequest that spawned the Operation.
  public var createRecognizerRequest: Google_Cloud_Speech_V2_CreateRecognizerRequest {
    get {
      if case .createRecognizerRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_CreateRecognizerRequest()
    }
    set {request = .createRecognizerRequest(newValue)}
  }

  /// The UpdateRecognizerRequest that spawned the Operation.
  public var updateRecognizerRequest: Google_Cloud_Speech_V2_UpdateRecognizerRequest {
    get {
      if case .updateRecognizerRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UpdateRecognizerRequest()
    }
    set {request = .updateRecognizerRequest(newValue)}
  }

  /// The DeleteRecognizerRequest that spawned the Operation.
  public var deleteRecognizerRequest: Google_Cloud_Speech_V2_DeleteRecognizerRequest {
    get {
      if case .deleteRecognizerRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_DeleteRecognizerRequest()
    }
    set {request = .deleteRecognizerRequest(newValue)}
  }

  /// The UndeleteRecognizerRequest that spawned the Operation.
  public var undeleteRecognizerRequest: Google_Cloud_Speech_V2_UndeleteRecognizerRequest {
    get {
      if case .undeleteRecognizerRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UndeleteRecognizerRequest()
    }
    set {request = .undeleteRecognizerRequest(newValue)}
  }

  /// The CreateCustomClassRequest that spawned the Operation.
  public var createCustomClassRequest: Google_Cloud_Speech_V2_CreateCustomClassRequest {
    get {
      if case .createCustomClassRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_CreateCustomClassRequest()
    }
    set {request = .createCustomClassRequest(newValue)}
  }

  /// The UpdateCustomClassRequest that spawned the Operation.
  public var updateCustomClassRequest: Google_Cloud_Speech_V2_UpdateCustomClassRequest {
    get {
      if case .updateCustomClassRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UpdateCustomClassRequest()
    }
    set {request = .updateCustomClassRequest(newValue)}
  }

  /// The DeleteCustomClassRequest that spawned the Operation.
  public var deleteCustomClassRequest: Google_Cloud_Speech_V2_DeleteCustomClassRequest {
    get {
      if case .deleteCustomClassRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_DeleteCustomClassRequest()
    }
    set {request = .deleteCustomClassRequest(newValue)}
  }

  /// The UndeleteCustomClassRequest that spawned the Operation.
  public var undeleteCustomClassRequest: Google_Cloud_Speech_V2_UndeleteCustomClassRequest {
    get {
      if case .undeleteCustomClassRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UndeleteCustomClassRequest()
    }
    set {request = .undeleteCustomClassRequest(newValue)}
  }

  /// The CreatePhraseSetRequest that spawned the Operation.
  public var createPhraseSetRequest: Google_Cloud_Speech_V2_CreatePhraseSetRequest {
    get {
      if case .createPhraseSetRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_CreatePhraseSetRequest()
    }
    set {request = .createPhraseSetRequest(newValue)}
  }

  /// The UpdatePhraseSetRequest that spawned the Operation.
  public var updatePhraseSetRequest: Google_Cloud_Speech_V2_UpdatePhraseSetRequest {
    get {
      if case .updatePhraseSetRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UpdatePhraseSetRequest()
    }
    set {request = .updatePhraseSetRequest(newValue)}
  }

  /// The DeletePhraseSetRequest that spawned the Operation.
  public var deletePhraseSetRequest: Google_Cloud_Speech_V2_DeletePhraseSetRequest {
    get {
      if case .deletePhraseSetRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_DeletePhraseSetRequest()
    }
    set {request = .deletePhraseSetRequest(newValue)}
  }

  /// The UndeletePhraseSetRequest that spawned the Operation.
  public var undeletePhraseSetRequest: Google_Cloud_Speech_V2_UndeletePhraseSetRequest {
    get {
      if case .undeletePhraseSetRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UndeletePhraseSetRequest()
    }
    set {request = .undeletePhraseSetRequest(newValue)}
  }

  /// The UpdateConfigRequest that spawned the Operation.
  public var updateConfigRequest: Google_Cloud_Speech_V2_UpdateConfigRequest {
    get {
      if case .updateConfigRequest(let v)? = request {return v}
      return Google_Cloud_Speech_V2_UpdateConfigRequest()
    }
    set {request = .updateConfigRequest(newValue)}
  }

  /// The percent progress of the Operation. Values can range from 0-100. If the
  /// value is 100, then the operation is finished.
  public var progressPercent: Int32 = 0

  /// Specific metadata per RPC.
  public var metadata: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Metadata? = nil

  /// Metadata specific to the BatchRecognize method.
  public var batchRecognizeMetadata: Google_Cloud_Speech_V2_BatchRecognizeMetadata {
    get {
      if case .batchRecognizeMetadata(let v)? = metadata {return v}
      return Google_Cloud_Speech_V2_BatchRecognizeMetadata()
    }
    set {metadata = .batchRecognizeMetadata(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The request that spawned the Operation.
  public enum OneOf_Request: Equatable {
    /// The BatchRecognizeRequest that spawned the Operation.
    case batchRecognizeRequest(Google_Cloud_Speech_V2_BatchRecognizeRequest)
    /// The CreateRecognizerRequest that spawned the Operation.
    case createRecognizerRequest(Google_Cloud_Speech_V2_CreateRecognizerRequest)
    /// The UpdateRecognizerRequest that spawned the Operation.
    case updateRecognizerRequest(Google_Cloud_Speech_V2_UpdateRecognizerRequest)
    /// The DeleteRecognizerRequest that spawned the Operation.
    case deleteRecognizerRequest(Google_Cloud_Speech_V2_DeleteRecognizerRequest)
    /// The UndeleteRecognizerRequest that spawned the Operation.
    case undeleteRecognizerRequest(Google_Cloud_Speech_V2_UndeleteRecognizerRequest)
    /// The CreateCustomClassRequest that spawned the Operation.
    case createCustomClassRequest(Google_Cloud_Speech_V2_CreateCustomClassRequest)
    /// The UpdateCustomClassRequest that spawned the Operation.
    case updateCustomClassRequest(Google_Cloud_Speech_V2_UpdateCustomClassRequest)
    /// The DeleteCustomClassRequest that spawned the Operation.
    case deleteCustomClassRequest(Google_Cloud_Speech_V2_DeleteCustomClassRequest)
    /// The UndeleteCustomClassRequest that spawned the Operation.
    case undeleteCustomClassRequest(Google_Cloud_Speech_V2_UndeleteCustomClassRequest)
    /// The CreatePhraseSetRequest that spawned the Operation.
    case createPhraseSetRequest(Google_Cloud_Speech_V2_CreatePhraseSetRequest)
    /// The UpdatePhraseSetRequest that spawned the Operation.
    case updatePhraseSetRequest(Google_Cloud_Speech_V2_UpdatePhraseSetRequest)
    /// The DeletePhraseSetRequest that spawned the Operation.
    case deletePhraseSetRequest(Google_Cloud_Speech_V2_DeletePhraseSetRequest)
    /// The UndeletePhraseSetRequest that spawned the Operation.
    case undeletePhraseSetRequest(Google_Cloud_Speech_V2_UndeletePhraseSetRequest)
    /// The UpdateConfigRequest that spawned the Operation.
    case updateConfigRequest(Google_Cloud_Speech_V2_UpdateConfigRequest)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Request, rhs: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Request) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.batchRecognizeRequest, .batchRecognizeRequest): return {
        guard case .batchRecognizeRequest(let l) = lhs, case .batchRecognizeRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.createRecognizerRequest, .createRecognizerRequest): return {
        guard case .createRecognizerRequest(let l) = lhs, case .createRecognizerRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.updateRecognizerRequest, .updateRecognizerRequest): return {
        guard case .updateRecognizerRequest(let l) = lhs, case .updateRecognizerRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.deleteRecognizerRequest, .deleteRecognizerRequest): return {
        guard case .deleteRecognizerRequest(let l) = lhs, case .deleteRecognizerRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.undeleteRecognizerRequest, .undeleteRecognizerRequest): return {
        guard case .undeleteRecognizerRequest(let l) = lhs, case .undeleteRecognizerRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.createCustomClassRequest, .createCustomClassRequest): return {
        guard case .createCustomClassRequest(let l) = lhs, case .createCustomClassRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.updateCustomClassRequest, .updateCustomClassRequest): return {
        guard case .updateCustomClassRequest(let l) = lhs, case .updateCustomClassRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.deleteCustomClassRequest, .deleteCustomClassRequest): return {
        guard case .deleteCustomClassRequest(let l) = lhs, case .deleteCustomClassRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.undeleteCustomClassRequest, .undeleteCustomClassRequest): return {
        guard case .undeleteCustomClassRequest(let l) = lhs, case .undeleteCustomClassRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.createPhraseSetRequest, .createPhraseSetRequest): return {
        guard case .createPhraseSetRequest(let l) = lhs, case .createPhraseSetRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.updatePhraseSetRequest, .updatePhraseSetRequest): return {
        guard case .updatePhraseSetRequest(let l) = lhs, case .updatePhraseSetRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.deletePhraseSetRequest, .deletePhraseSetRequest): return {
        guard case .deletePhraseSetRequest(let l) = lhs, case .deletePhraseSetRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.undeletePhraseSetRequest, .undeletePhraseSetRequest): return {
        guard case .undeletePhraseSetRequest(let l) = lhs, case .undeletePhraseSetRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.updateConfigRequest, .updateConfigRequest): return {
        guard case .updateConfigRequest(let l) = lhs, case .updateConfigRequest(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  /// Specific metadata per RPC.
  public enum OneOf_Metadata: Equatable {
    /// Metadata specific to the BatchRecognize method.
    case batchRecognizeMetadata(Google_Cloud_Speech_V2_BatchRecognizeMetadata)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Metadata, rhs: Google_Cloud_Speech_V2_OperationMetadata.OneOf_Metadata) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.batchRecognizeMetadata, .batchRecognizeMetadata): return {
        guard case .batchRecognizeMetadata(let l) = lhs, case .batchRecognizeMetadata(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
  fileprivate var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Request message for the
/// [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
public struct Google_Cloud_Speech_V2_ListRecognizersRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The project and location of Recognizers to list. The expected
  /// format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  /// The maximum number of Recognizers to return. The service may return fewer
  /// than this value. If unspecified, at most 5 Recognizers will be returned.
  /// The maximum value is 100; values above 100 will be coerced to 100.
  public var pageSize: Int32 = 0

  /// A page token, received from a previous
  /// [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] call.
  /// Provide this to retrieve the subsequent page.
  ///
  /// When paginating, all other parameters provided to
  /// [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] must match
  /// the call that provided the page token.
  public var pageToken: String = String()

  /// Whether, or not, to show resources that have been deleted.
  public var showDeleted: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for the
/// [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] method.
public struct Google_Cloud_Speech_V2_ListRecognizersResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The list of requested Recognizers.
  public var recognizers: [Google_Cloud_Speech_V2_Recognizer] = []

  /// A token, which can be sent as
  /// [page_token][google.cloud.speech.v2.ListRecognizersRequest.page_token] to
  /// retrieve the next page. If this field is omitted, there are no subsequent
  /// pages. This token expires after 72 hours.
  public var nextPageToken: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [GetRecognizer][google.cloud.speech.v2.Speech.GetRecognizer] method.
public struct Google_Cloud_Speech_V2_GetRecognizerRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to retrieve. The expected format is
  /// `projects/{project}/locations/{location}/recognizers/{recognizer}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UpdateRecognizer][google.cloud.speech.v2.Speech.UpdateRecognizer] method.
public struct Google_Cloud_Speech_V2_UpdateRecognizerRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The Recognizer to update.
  ///
  /// The Recognizer's `name` field is used to identify the Recognizer to update.
  /// Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
  public var recognizer: Google_Cloud_Speech_V2_Recognizer {
    get {return _recognizer ?? Google_Cloud_Speech_V2_Recognizer()}
    set {_recognizer = newValue}
  }
  /// Returns true if `recognizer` has been explicitly set.
  public var hasRecognizer: Bool {return self._recognizer != nil}
  /// Clears the value of `recognizer`. Subsequent reads from it will return its default value.
  public mutating func clearRecognizer() {self._recognizer = nil}

  /// The list of fields to update. If empty, all non-default valued fields are
  /// considered for update. Use `*` to update the entire Recognizer resource.
  public var updateMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _updateMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_updateMask = newValue}
  }
  /// Returns true if `updateMask` has been explicitly set.
  public var hasUpdateMask: Bool {return self._updateMask != nil}
  /// Clears the value of `updateMask`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateMask() {self._updateMask = nil}

  /// If set, validate the request and preview the updated Recognizer, but do not
  /// actually update it.
  public var validateOnly: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _recognizer: Google_Cloud_Speech_V2_Recognizer? = nil
  fileprivate var _updateMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// Request message for the
/// [DeleteRecognizer][google.cloud.speech.v2.Speech.DeleteRecognizer] method.
public struct Google_Cloud_Speech_V2_DeleteRecognizerRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to delete.
  /// Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
  public var name: String = String()

  /// If set, validate the request and preview the deleted Recognizer, but do not
  /// actually delete it.
  public var validateOnly: Bool = false

  /// If set to true, and the Recognizer is not found, the request will succeed
  /// and  be a no-op (no Operation is recorded in this case).
  public var allowMissing: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UndeleteRecognizer][google.cloud.speech.v2.Speech.UndeleteRecognizer]
/// method.
public struct Google_Cloud_Speech_V2_UndeleteRecognizerRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to undelete.
  /// Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`
  public var name: String = String()

  /// If set, validate the request and preview the undeleted Recognizer, but do
  /// not actually undelete it.
  public var validateOnly: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A Recognizer message. Stores recognition configuration and metadata.
public struct Google_Cloud_Speech_V2_Recognizer {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The resource name of the Recognizer.
  /// Format: `projects/{project}/locations/{location}/recognizers/{recognizer}`.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Output only. System-assigned unique identifier for the Recognizer.
  public var uid: String {
    get {return _storage._uid}
    set {_uniqueStorage()._uid = newValue}
  }

  /// User-settable, human-readable name for the Recognizer. Must be 63
  /// characters or less.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// Optional. Which model to use for recognition requests. Select the model
  /// best suited to your domain to get best results.
  ///
  /// Guidance for choosing which model to use can be found in the [Transcription
  /// Models
  /// Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
  /// and the models supported in each region can be found in the [Table Of
  /// Supported
  /// Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
  public var model: String {
    get {return _storage._model}
    set {_uniqueStorage()._model = newValue}
  }

  /// Optional. The language of the supplied audio as a
  /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
  ///
  /// Supported languages for each model are listed in the [Table of Supported
  /// Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
  ///
  /// If additional languages are provided, recognition result will contain
  /// recognition in the most likely language detected. The recognition result
  /// will include the language tag of the language detected in the audio.
  /// When you create or update a Recognizer, these values are
  /// stored in normalized BCP-47 form. For example, "en-us" is stored as
  /// "en-US".
  public var languageCodes: [String] {
    get {return _storage._languageCodes}
    set {_uniqueStorage()._languageCodes = newValue}
  }

  /// Default configuration to use for requests with this Recognizer.
  /// This can be overwritten by inline configuration in the
  /// [RecognizeRequest.config][google.cloud.speech.v2.RecognizeRequest.config]
  /// field.
  public var defaultRecognitionConfig: Google_Cloud_Speech_V2_RecognitionConfig {
    get {return _storage._defaultRecognitionConfig ?? Google_Cloud_Speech_V2_RecognitionConfig()}
    set {_uniqueStorage()._defaultRecognitionConfig = newValue}
  }
  /// Returns true if `defaultRecognitionConfig` has been explicitly set.
  public var hasDefaultRecognitionConfig: Bool {return _storage._defaultRecognitionConfig != nil}
  /// Clears the value of `defaultRecognitionConfig`. Subsequent reads from it will return its default value.
  public mutating func clearDefaultRecognitionConfig() {_uniqueStorage()._defaultRecognitionConfig = nil}

  /// Allows users to store small amounts of arbitrary data.
  /// Both the key and the value must be 63 characters or less each.
  /// At most 100 annotations.
  public var annotations: Dictionary<String,String> {
    get {return _storage._annotations}
    set {_uniqueStorage()._annotations = newValue}
  }

  /// Output only. The Recognizer lifecycle state.
  public var state: Google_Cloud_Speech_V2_Recognizer.State {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Output only. Creation time.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. The most recent time this Recognizer was modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. The time at which this Recognizer was requested for deletion.
  public var deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._deleteTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._deleteTime = newValue}
  }
  /// Returns true if `deleteTime` has been explicitly set.
  public var hasDeleteTime: Bool {return _storage._deleteTime != nil}
  /// Clears the value of `deleteTime`. Subsequent reads from it will return its default value.
  public mutating func clearDeleteTime() {_uniqueStorage()._deleteTime = nil}

  /// Output only. The time at which this Recognizer will be purged.
  public var expireTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._expireTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._expireTime = newValue}
  }
  /// Returns true if `expireTime` has been explicitly set.
  public var hasExpireTime: Bool {return _storage._expireTime != nil}
  /// Clears the value of `expireTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpireTime() {_uniqueStorage()._expireTime = nil}

  /// Output only. This checksum is computed by the server based on the value of
  /// other fields. This may be sent on update, undelete, and delete requests to
  /// ensure the client has an up-to-date value before proceeding.
  public var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. Whether or not this Recognizer is in the process of being
  /// updated.
  public var reconciling: Bool {
    get {return _storage._reconciling}
    set {_uniqueStorage()._reconciling = newValue}
  }

  /// Output only. The [KMS key
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
  /// the Recognizer is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
  public var kmsKeyName: String {
    get {return _storage._kmsKeyName}
    set {_uniqueStorage()._kmsKeyName = newValue}
  }

  /// Output only. The [KMS key version
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
  /// with which the Recognizer is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
  public var kmsKeyVersionName: String {
    get {return _storage._kmsKeyVersionName}
    set {_uniqueStorage()._kmsKeyVersionName = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Set of states that define the lifecycle of a Recognizer.
  public enum State: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// The default value. This value is used if the state is omitted.
    case unspecified // = 0

    /// The Recognizer is active and ready for use.
    case active // = 2

    /// This Recognizer has been deleted.
    case deleted // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 2: self = .active
      case 4: self = .deleted
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .active: return 2
      case .deleted: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_Recognizer.State: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_Recognizer.State] = [
    .unspecified,
    .active,
    .deleted,
  ]
}

#endif  // swift(>=4.2)

/// Automatically detected decoding parameters.
/// Supported for the following encodings:
///
/// * WAV_LINEAR16: 16-bit signed little-endian PCM samples in a WAV container.
///
/// * WAV_MULAW: 8-bit companded mulaw samples in a WAV container.
///
/// * WAV_ALAW: 8-bit companded alaw samples in a WAV container.
///
/// * RFC4867_5_AMR: AMR frames with an rfc4867.5 header.
///
/// * RFC4867_5_AMRWB: AMR-WB frames with an rfc4867.5 header.
///
/// * FLAC: FLAC frames in the "native FLAC" container format.
///
/// * MP3: MPEG audio frames with optional (ignored) ID3 metadata.
///
/// * OGG_OPUS: Opus audio frames in an Ogg container.
///
/// * WEBM_OPUS: Opus audio frames in a WebM container.
public struct Google_Cloud_Speech_V2_AutoDetectDecodingConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Explicitly specified decoding parameters.
public struct Google_Cloud_Speech_V2_ExplicitDecodingConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Encoding of the audio data sent for recognition.
  public var encoding: Google_Cloud_Speech_V2_ExplicitDecodingConfig.AudioEncoding = .unspecified

  /// Sample rate in Hertz of the audio data sent for recognition. Valid
  /// values are: 8000-48000. 16000 is optimal. For best results, set the
  /// sampling rate of the audio source to 16000 Hz. If that's not possible, use
  /// the native sample rate of the audio source (instead of re-sampling).
  /// Supported for the following encodings:
  ///
  /// * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
  ///
  /// * MULAW: Headerless 8-bit companded mulaw samples.
  ///
  /// * ALAW: Headerless 8-bit companded alaw samples.
  public var sampleRateHertz: Int32 = 0

  /// Number of channels present in the audio data sent for recognition.
  /// Supported for the following encodings:
  ///
  /// * LINEAR16: Headerless 16-bit signed little-endian PCM samples.
  ///
  /// * MULAW: Headerless 8-bit companded mulaw samples.
  ///
  /// * ALAW: Headerless 8-bit companded alaw samples.
  ///
  /// The maximum allowed value is 8.
  public var audioChannelCount: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Supported audio data encodings.
  public enum AudioEncoding: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Default value. This value is unused.
    case unspecified // = 0

    /// Headerless 16-bit signed little-endian PCM samples.
    case linear16 // = 1

    /// Headerless 8-bit companded mulaw samples.
    case mulaw // = 2

    /// Headerless 8-bit companded alaw samples.
    case alaw // = 3
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .linear16
      case 2: self = .mulaw
      case 3: self = .alaw
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .linear16: return 1
      case .mulaw: return 2
      case .alaw: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_ExplicitDecodingConfig.AudioEncoding: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_ExplicitDecodingConfig.AudioEncoding] = [
    .unspecified,
    .linear16,
    .mulaw,
    .alaw,
  ]
}

#endif  // swift(>=4.2)

/// Configuration to enable speaker diarization.
public struct Google_Cloud_Speech_V2_SpeakerDiarizationConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Minimum number of speakers in the conversation. This range gives
  /// you more flexibility by allowing the system to automatically determine the
  /// correct number of speakers.
  ///
  /// To fix the number of speakers detected in the audio, set
  /// `min_speaker_count` = `max_speaker_count`.
  public var minSpeakerCount: Int32 = 0

  /// Required. Maximum number of speakers in the conversation. Valid values are:
  /// 1-6. Must be >= `min_speaker_count`. This range gives you more flexibility
  /// by allowing the system to automatically determine the correct number of
  /// speakers.
  public var maxSpeakerCount: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Available recognition features.
public struct Google_Cloud_Speech_V2_RecognitionFeatures {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If set to `true`, the server will attempt to filter out profanities,
  /// replacing all but the initial character in each filtered word with
  /// asterisks, for instance, "f***". If set to `false` or omitted, profanities
  /// won't be filtered out.
  public var profanityFilter: Bool = false

  /// If `true`, the top result includes a list of words and the start and end
  /// time offsets (timestamps) for those words. If `false`, no word-level time
  /// offset information is returned. The default is `false`.
  public var enableWordTimeOffsets: Bool = false

  /// If `true`, the top result includes a list of words and the confidence for
  /// those words. If `false`, no word-level confidence information is returned.
  /// The default is `false`.
  public var enableWordConfidence: Bool = false

  /// If `true`, adds punctuation to recognition result hypotheses. This feature
  /// is only available in select languages. The default `false` value does not
  /// add punctuation to result hypotheses.
  public var enableAutomaticPunctuation: Bool = false

  /// The spoken punctuation behavior for the call. If `true`, replaces spoken
  /// punctuation with the corresponding symbols in the request. For example,
  /// "how are you question mark" becomes "how are you?". See
  /// https://cloud.google.com/speech-to-text/docs/spoken-punctuation for
  /// support. If `false`, spoken punctuation is not replaced.
  public var enableSpokenPunctuation: Bool = false

  /// The spoken emoji behavior for the call. If `true`, adds spoken emoji
  /// formatting for the request. This will replace spoken emojis with the
  /// corresponding Unicode symbols in the final transcript. If `false`, spoken
  /// emojis are not replaced.
  public var enableSpokenEmojis: Bool = false

  /// Mode for recognizing multi-channel audio.
  public var multiChannelMode: Google_Cloud_Speech_V2_RecognitionFeatures.MultiChannelMode = .unspecified

  /// Configuration to enable speaker diarization and set additional
  /// parameters to make diarization better suited for your application.
  /// When this is enabled, we send all the words from the beginning of the
  /// audio for the top alternative in every consecutive STREAMING responses.
  /// This is done in order to improve our speaker tags as our models learn to
  /// identify the speakers in the conversation over time.
  /// For non-streaming requests, the diarization results will be provided only
  /// in the top alternative of the FINAL SpeechRecognitionResult.
  public var diarizationConfig: Google_Cloud_Speech_V2_SpeakerDiarizationConfig {
    get {return _diarizationConfig ?? Google_Cloud_Speech_V2_SpeakerDiarizationConfig()}
    set {_diarizationConfig = newValue}
  }
  /// Returns true if `diarizationConfig` has been explicitly set.
  public var hasDiarizationConfig: Bool {return self._diarizationConfig != nil}
  /// Clears the value of `diarizationConfig`. Subsequent reads from it will return its default value.
  public mutating func clearDiarizationConfig() {self._diarizationConfig = nil}

  /// Maximum number of recognition hypotheses to be returned.
  /// The server may return fewer than `max_alternatives`.
  /// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
  /// one. If omitted, will return a maximum of one.
  public var maxAlternatives: Int32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Options for how to recognize multi-channel audio.
  public enum MultiChannelMode: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Default value for the multi-channel mode. If the audio contains
    /// multiple channels, only the first channel will be transcribed; other
    /// channels will be ignored.
    case unspecified // = 0

    /// If selected, each channel in the provided audio is transcribed
    /// independently. This cannot be selected if the selected
    /// [model][google.cloud.speech.v2.Recognizer.model] is `latest_short`.
    case separateRecognitionPerChannel // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .separateRecognitionPerChannel
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .separateRecognitionPerChannel: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _diarizationConfig: Google_Cloud_Speech_V2_SpeakerDiarizationConfig? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_RecognitionFeatures.MultiChannelMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_RecognitionFeatures.MultiChannelMode] = [
    .unspecified,
    .separateRecognitionPerChannel,
  ]
}

#endif  // swift(>=4.2)

/// Provides "hints" to the speech recognizer to favor specific words and phrases
/// in the results. PhraseSets can be specified as an inline resource, or a
/// reference to an existing PhraseSet resource.
public struct Google_Cloud_Speech_V2_SpeechAdaptation {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// A list of inline or referenced PhraseSets.
  public var phraseSets: [Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet] = []

  /// A list of inline CustomClasses. Existing CustomClass resources can be
  /// referenced directly in a PhraseSet.
  public var customClasses: [Google_Cloud_Speech_V2_CustomClass] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// A biasing PhraseSet, which can be either a string referencing the name of
  /// an existing PhraseSets resource, or an inline definition of a PhraseSet.
  public struct AdaptationPhraseSet {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    public var value: Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet.OneOf_Value? = nil

    /// The name of an existing PhraseSet resource. The user must have read
    /// access to the resource and it must not be deleted.
    public var phraseSet: String {
      get {
        if case .phraseSet(let v)? = value {return v}
        return String()
      }
      set {value = .phraseSet(newValue)}
    }

    /// An inline defined PhraseSet.
    public var inlinePhraseSet: Google_Cloud_Speech_V2_PhraseSet {
      get {
        if case .inlinePhraseSet(let v)? = value {return v}
        return Google_Cloud_Speech_V2_PhraseSet()
      }
      set {value = .inlinePhraseSet(newValue)}
    }

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public enum OneOf_Value: Equatable {
      /// The name of an existing PhraseSet resource. The user must have read
      /// access to the resource and it must not be deleted.
      case phraseSet(String)
      /// An inline defined PhraseSet.
      case inlinePhraseSet(Google_Cloud_Speech_V2_PhraseSet)

    #if !swift(>=4.1)
      public static func ==(lhs: Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet.OneOf_Value, rhs: Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet.OneOf_Value) -> Bool {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch (lhs, rhs) {
        case (.phraseSet, .phraseSet): return {
          guard case .phraseSet(let l) = lhs, case .phraseSet(let r) = rhs else { preconditionFailure() }
          return l == r
        }()
        case (.inlinePhraseSet, .inlinePhraseSet): return {
          guard case .inlinePhraseSet(let l) = lhs, case .inlinePhraseSet(let r) = rhs else { preconditionFailure() }
          return l == r
        }()
        default: return false
        }
      }
    #endif
    }

    public init() {}
  }

  public init() {}
}

/// Provides information to the Recognizer that specifies how to process the
/// recognition request.
public struct Google_Cloud_Speech_V2_RecognitionConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Decoding parameters for audio being sent for recognition.
  public var decodingConfig: OneOf_DecodingConfig? {
    get {return _storage._decodingConfig}
    set {_uniqueStorage()._decodingConfig = newValue}
  }

  /// Automatically detect decoding parameters.
  /// Preferred for supported formats.
  public var autoDecodingConfig: Google_Cloud_Speech_V2_AutoDetectDecodingConfig {
    get {
      if case .autoDecodingConfig(let v)? = _storage._decodingConfig {return v}
      return Google_Cloud_Speech_V2_AutoDetectDecodingConfig()
    }
    set {_uniqueStorage()._decodingConfig = .autoDecodingConfig(newValue)}
  }

  /// Explicitly specified decoding parameters.
  /// Required if using headerless PCM audio (linear16, mulaw, alaw).
  public var explicitDecodingConfig: Google_Cloud_Speech_V2_ExplicitDecodingConfig {
    get {
      if case .explicitDecodingConfig(let v)? = _storage._decodingConfig {return v}
      return Google_Cloud_Speech_V2_ExplicitDecodingConfig()
    }
    set {_uniqueStorage()._decodingConfig = .explicitDecodingConfig(newValue)}
  }

  /// Optional. Which model to use for recognition requests. Select the model
  /// best suited to your domain to get best results.
  ///
  /// Guidance for choosing which model to use can be found in the [Transcription
  /// Models
  /// Documentation](https://cloud.google.com/speech-to-text/v2/docs/transcription-model)
  /// and the models supported in each region can be found in the [Table Of
  /// Supported
  /// Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
  public var model: String {
    get {return _storage._model}
    set {_uniqueStorage()._model = newValue}
  }

  /// Optional. The language of the supplied audio as a
  /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
  /// Language tags are normalized to BCP-47 before they are used eg "en-us"
  /// becomes "en-US".
  ///
  /// Supported languages for each model are listed in the [Table of Supported
  /// Models](https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages).
  ///
  /// If additional languages are provided, recognition result will contain
  /// recognition in the most likely language detected. The recognition result
  /// will include the language tag of the language detected in the audio.
  public var languageCodes: [String] {
    get {return _storage._languageCodes}
    set {_uniqueStorage()._languageCodes = newValue}
  }

  /// Speech recognition features to enable.
  public var features: Google_Cloud_Speech_V2_RecognitionFeatures {
    get {return _storage._features ?? Google_Cloud_Speech_V2_RecognitionFeatures()}
    set {_uniqueStorage()._features = newValue}
  }
  /// Returns true if `features` has been explicitly set.
  public var hasFeatures: Bool {return _storage._features != nil}
  /// Clears the value of `features`. Subsequent reads from it will return its default value.
  public mutating func clearFeatures() {_uniqueStorage()._features = nil}

  /// Speech adaptation context that weights recognizer predictions for specific
  /// words and phrases.
  public var adaptation: Google_Cloud_Speech_V2_SpeechAdaptation {
    get {return _storage._adaptation ?? Google_Cloud_Speech_V2_SpeechAdaptation()}
    set {_uniqueStorage()._adaptation = newValue}
  }
  /// Returns true if `adaptation` has been explicitly set.
  public var hasAdaptation: Bool {return _storage._adaptation != nil}
  /// Clears the value of `adaptation`. Subsequent reads from it will return its default value.
  public mutating func clearAdaptation() {_uniqueStorage()._adaptation = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Decoding parameters for audio being sent for recognition.
  public enum OneOf_DecodingConfig: Equatable {
    /// Automatically detect decoding parameters.
    /// Preferred for supported formats.
    case autoDecodingConfig(Google_Cloud_Speech_V2_AutoDetectDecodingConfig)
    /// Explicitly specified decoding parameters.
    /// Required if using headerless PCM audio (linear16, mulaw, alaw).
    case explicitDecodingConfig(Google_Cloud_Speech_V2_ExplicitDecodingConfig)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionConfig.OneOf_DecodingConfig, rhs: Google_Cloud_Speech_V2_RecognitionConfig.OneOf_DecodingConfig) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.autoDecodingConfig, .autoDecodingConfig): return {
        guard case .autoDecodingConfig(let l) = lhs, case .autoDecodingConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.explicitDecodingConfig, .explicitDecodingConfig): return {
        guard case .explicitDecodingConfig(let l) = lhs, case .explicitDecodingConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

/// Request message for the
/// [Recognize][google.cloud.speech.v2.Speech.Recognize] method. Either
/// `content` or `uri` must be supplied. Supplying both or neither returns
/// [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See [content
/// limits](https://cloud.google.com/speech-to-text/quotas#content).
public struct Google_Cloud_Speech_V2_RecognizeRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to use during recognition. The
  /// expected format is
  /// `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
  /// {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
  public var recognizer: String = String()

  /// Features and audio metadata to use for the Automatic Speech Recognition.
  /// This field in combination with the
  /// [config_mask][google.cloud.speech.v2.RecognizeRequest.config_mask] field
  /// can be used to override parts of the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the Recognizer resource.
  public var config: Google_Cloud_Speech_V2_RecognitionConfig {
    get {return _config ?? Google_Cloud_Speech_V2_RecognitionConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  /// The list of fields in
  /// [config][google.cloud.speech.v2.RecognizeRequest.config] that override the
  /// values in the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the recognizer during this recognition request. If no mask is provided,
  /// all non-default valued fields in
  /// [config][google.cloud.speech.v2.RecognizeRequest.config] override the
  /// values in the recognizer for this recognition request. If a mask is
  /// provided, only the fields listed in the mask override the config in the
  /// recognizer for this recognition request. If a wildcard (`*`) is provided,
  /// [config][google.cloud.speech.v2.RecognizeRequest.config] completely
  /// overrides and replaces the config in the recognizer for this recognition
  /// request.
  public var configMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _configMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_configMask = newValue}
  }
  /// Returns true if `configMask` has been explicitly set.
  public var hasConfigMask: Bool {return self._configMask != nil}
  /// Clears the value of `configMask`. Subsequent reads from it will return its default value.
  public mutating func clearConfigMask() {self._configMask = nil}

  /// The audio source, which is either inline content or a Google Cloud
  /// Storage URI.
  public var audioSource: Google_Cloud_Speech_V2_RecognizeRequest.OneOf_AudioSource? = nil

  /// The audio data bytes encoded as specified in
  /// [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. As
  /// with all bytes fields, proto buffers use a pure binary representation,
  /// whereas JSON representations use base64.
  public var content: Data {
    get {
      if case .content(let v)? = audioSource {return v}
      return Data()
    }
    set {audioSource = .content(newValue)}
  }

  /// URI that points to a file that contains audio data bytes as specified in
  /// [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. The file
  /// must not be compressed (for example, gzip). Currently, only Google Cloud
  /// Storage URIs are supported, which must be specified in the following
  /// format: `gs://bucket_name/object_name` (other URI formats return
  /// [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more
  /// information, see [Request
  /// URIs](https://cloud.google.com/storage/docs/reference-uris).
  public var uri: String {
    get {
      if case .uri(let v)? = audioSource {return v}
      return String()
    }
    set {audioSource = .uri(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The audio source, which is either inline content or a Google Cloud
  /// Storage URI.
  public enum OneOf_AudioSource: Equatable {
    /// The audio data bytes encoded as specified in
    /// [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. As
    /// with all bytes fields, proto buffers use a pure binary representation,
    /// whereas JSON representations use base64.
    case content(Data)
    /// URI that points to a file that contains audio data bytes as specified in
    /// [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. The file
    /// must not be compressed (for example, gzip). Currently, only Google Cloud
    /// Storage URIs are supported, which must be specified in the following
    /// format: `gs://bucket_name/object_name` (other URI formats return
    /// [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more
    /// information, see [Request
    /// URIs](https://cloud.google.com/storage/docs/reference-uris).
    case uri(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_RecognizeRequest.OneOf_AudioSource, rhs: Google_Cloud_Speech_V2_RecognizeRequest.OneOf_AudioSource) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.content, .content): return {
        guard case .content(let l) = lhs, case .content(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.uri, .uri): return {
        guard case .uri(let l) = lhs, case .uri(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _config: Google_Cloud_Speech_V2_RecognitionConfig? = nil
  fileprivate var _configMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// Metadata about the recognition request and response.
public struct Google_Cloud_Speech_V2_RecognitionResponseMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// When available, billed audio seconds for the corresponding request.
  public var totalBilledDuration: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _totalBilledDuration ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_totalBilledDuration = newValue}
  }
  /// Returns true if `totalBilledDuration` has been explicitly set.
  public var hasTotalBilledDuration: Bool {return self._totalBilledDuration != nil}
  /// Clears the value of `totalBilledDuration`. Subsequent reads from it will return its default value.
  public mutating func clearTotalBilledDuration() {self._totalBilledDuration = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _totalBilledDuration: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Alternative hypotheses (a.k.a. n-best list).
public struct Google_Cloud_Speech_V2_SpeechRecognitionAlternative {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Transcript text representing the words that the user spoke.
  public var transcript: String = String()

  /// The confidence estimate between 0.0 and 1.0. A higher number
  /// indicates an estimated greater likelihood that the recognized words are
  /// correct. This field is set only for the top alternative of a non-streaming
  /// result or, of a streaming result where
  /// [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
  /// set to `true`. This field is not guaranteed to be accurate and users should
  /// not rely on it to be always provided. The default of 0.0 is a sentinel
  /// value indicating `confidence` was not set.
  public var confidence: Float = 0

  /// A list of word-specific information for each recognized word.
  /// When the
  /// [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
  /// is set, you will see all the words from the beginning of the audio.
  public var words: [Google_Cloud_Speech_V2_WordInfo] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Word-specific information for recognized words.
public struct Google_Cloud_Speech_V2_WordInfo {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Time offset relative to the beginning of the audio,
  /// and corresponding to the start of the spoken word.
  /// This field is only set if
  /// [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
  /// is `true` and only in the top hypothesis. This is an experimental feature
  /// and the accuracy of the time offset can vary.
  public var startOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _startOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_startOffset = newValue}
  }
  /// Returns true if `startOffset` has been explicitly set.
  public var hasStartOffset: Bool {return self._startOffset != nil}
  /// Clears the value of `startOffset`. Subsequent reads from it will return its default value.
  public mutating func clearStartOffset() {self._startOffset = nil}

  /// Time offset relative to the beginning of the audio,
  /// and corresponding to the end of the spoken word.
  /// This field is only set if
  /// [enable_word_time_offsets][google.cloud.speech.v2.RecognitionFeatures.enable_word_time_offsets]
  /// is `true` and only in the top hypothesis. This is an experimental feature
  /// and the accuracy of the time offset can vary.
  public var endOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _endOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_endOffset = newValue}
  }
  /// Returns true if `endOffset` has been explicitly set.
  public var hasEndOffset: Bool {return self._endOffset != nil}
  /// Clears the value of `endOffset`. Subsequent reads from it will return its default value.
  public mutating func clearEndOffset() {self._endOffset = nil}

  /// The word corresponding to this set of information.
  public var word: String = String()

  /// The confidence estimate between 0.0 and 1.0. A higher number
  /// indicates an estimated greater likelihood that the recognized words are
  /// correct. This field is set only for the top alternative of a non-streaming
  /// result or, of a streaming result where
  /// [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final] is
  /// set to `true`. This field is not guaranteed to be accurate and users should
  /// not rely on it to be always provided. The default of 0.0 is a sentinel
  /// value indicating `confidence` was not set.
  public var confidence: Float = 0

  /// A distinct label is assigned for every speaker within the audio. This field
  /// specifies which one of those speakers was detected to have spoken this
  /// word. `speaker_label` is set if
  /// [SpeakerDiarizationConfig][google.cloud.speech.v2.SpeakerDiarizationConfig]
  /// is given and only in the top alternative.
  public var speakerLabel: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _startOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
  fileprivate var _endOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// A speech recognition result corresponding to a portion of the audio.
public struct Google_Cloud_Speech_V2_SpeechRecognitionResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// May contain one or more recognition hypotheses. These alternatives are
  /// ordered in terms of accuracy, with the top (first) alternative being the
  /// most probable, as ranked by the recognizer.
  public var alternatives: [Google_Cloud_Speech_V2_SpeechRecognitionAlternative] = []

  /// For multi-channel audio, this is the channel number corresponding to the
  /// recognized result for the audio from that channel.
  /// For `audio_channel_count` = `N`, its output values can range from `1` to
  /// `N`.
  public var channelTag: Int32 = 0

  /// Time offset of the end of this result relative to the beginning of the
  /// audio.
  public var resultEndOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _resultEndOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_resultEndOffset = newValue}
  }
  /// Returns true if `resultEndOffset` has been explicitly set.
  public var hasResultEndOffset: Bool {return self._resultEndOffset != nil}
  /// Clears the value of `resultEndOffset`. Subsequent reads from it will return its default value.
  public mutating func clearResultEndOffset() {self._resultEndOffset = nil}

  /// Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
  /// language tag of the language in this result. This language code was
  /// detected to have the most likelihood of being spoken in the audio.
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resultEndOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Response message for the
/// [Recognize][google.cloud.speech.v2.Speech.Recognize] method.
public struct Google_Cloud_Speech_V2_RecognizeResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Sequential list of transcription results corresponding to sequential
  /// portions of audio.
  public var results: [Google_Cloud_Speech_V2_SpeechRecognitionResult] = []

  /// Metadata about the recognition.
  public var metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata {
    get {return _metadata ?? Google_Cloud_Speech_V2_RecognitionResponseMetadata()}
    set {_metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return self._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {self._metadata = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata? = nil
}

/// Available recognition features specific to streaming recognition requests.
public struct Google_Cloud_Speech_V2_StreamingRecognitionFeatures {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// If `true`, responses with voice activity speech events will be returned as
  /// they are detected.
  public var enableVoiceActivityEvents: Bool = false

  /// Whether or not to stream interim results to the client. If set to true,
  /// interim results will be streamed to the client. Otherwise, only the final
  /// response will be streamed back.
  public var interimResults: Bool = false

  /// If set, the server will automatically close the stream after the specified
  /// duration has elapsed after the last VOICE_ACTIVITY speech event has been
  /// sent. The field `voice_activity_events` must also be set to true.
  public var voiceActivityTimeout: Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout {
    get {return _voiceActivityTimeout ?? Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout()}
    set {_voiceActivityTimeout = newValue}
  }
  /// Returns true if `voiceActivityTimeout` has been explicitly set.
  public var hasVoiceActivityTimeout: Bool {return self._voiceActivityTimeout != nil}
  /// Clears the value of `voiceActivityTimeout`. Subsequent reads from it will return its default value.
  public mutating func clearVoiceActivityTimeout() {self._voiceActivityTimeout = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Events that a timeout can be set on for voice activity.
  public struct VoiceActivityTimeout {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// Duration to timeout the stream if no speech begins. If this is set and
    /// no speech is detected in this duration at the start of the stream, the
    /// server will close the stream.
    public var speechStartTimeout: SwiftProtobuf.Google_Protobuf_Duration {
      get {return _speechStartTimeout ?? SwiftProtobuf.Google_Protobuf_Duration()}
      set {_speechStartTimeout = newValue}
    }
    /// Returns true if `speechStartTimeout` has been explicitly set.
    public var hasSpeechStartTimeout: Bool {return self._speechStartTimeout != nil}
    /// Clears the value of `speechStartTimeout`. Subsequent reads from it will return its default value.
    public mutating func clearSpeechStartTimeout() {self._speechStartTimeout = nil}

    /// Duration to timeout the stream after speech ends. If this is set and no
    /// speech is detected in this duration after speech was detected, the server
    /// will close the stream.
    public var speechEndTimeout: SwiftProtobuf.Google_Protobuf_Duration {
      get {return _speechEndTimeout ?? SwiftProtobuf.Google_Protobuf_Duration()}
      set {_speechEndTimeout = newValue}
    }
    /// Returns true if `speechEndTimeout` has been explicitly set.
    public var hasSpeechEndTimeout: Bool {return self._speechEndTimeout != nil}
    /// Clears the value of `speechEndTimeout`. Subsequent reads from it will return its default value.
    public mutating func clearSpeechEndTimeout() {self._speechEndTimeout = nil}

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}

    fileprivate var _speechStartTimeout: SwiftProtobuf.Google_Protobuf_Duration? = nil
    fileprivate var _speechEndTimeout: SwiftProtobuf.Google_Protobuf_Duration? = nil
  }

  public init() {}

  fileprivate var _voiceActivityTimeout: Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout? = nil
}

/// Provides configuration information for the StreamingRecognize request.
public struct Google_Cloud_Speech_V2_StreamingRecognitionConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. Features and audio metadata to use for the Automatic Speech
  /// Recognition. This field in combination with the
  /// [config_mask][google.cloud.speech.v2.StreamingRecognitionConfig.config_mask]
  /// field can be used to override parts of the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the Recognizer resource.
  public var config: Google_Cloud_Speech_V2_RecognitionConfig {
    get {return _config ?? Google_Cloud_Speech_V2_RecognitionConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  /// The list of fields in
  /// [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] that
  /// override the values in the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the recognizer during this recognition request. If no mask is provided,
  /// all non-default valued fields in
  /// [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] override
  /// the values in the Recognizer for this recognition request. If a mask is
  /// provided, only the fields listed in the mask override the config in the
  /// Recognizer for this recognition request. If a wildcard (`*`) is provided,
  /// [config][google.cloud.speech.v2.StreamingRecognitionConfig.config]
  /// completely overrides and replaces the config in the recognizer for this
  /// recognition request.
  public var configMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _configMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_configMask = newValue}
  }
  /// Returns true if `configMask` has been explicitly set.
  public var hasConfigMask: Bool {return self._configMask != nil}
  /// Clears the value of `configMask`. Subsequent reads from it will return its default value.
  public mutating func clearConfigMask() {self._configMask = nil}

  /// Speech recognition features to enable specific to streaming audio
  /// recognition requests.
  public var streamingFeatures: Google_Cloud_Speech_V2_StreamingRecognitionFeatures {
    get {return _streamingFeatures ?? Google_Cloud_Speech_V2_StreamingRecognitionFeatures()}
    set {_streamingFeatures = newValue}
  }
  /// Returns true if `streamingFeatures` has been explicitly set.
  public var hasStreamingFeatures: Bool {return self._streamingFeatures != nil}
  /// Clears the value of `streamingFeatures`. Subsequent reads from it will return its default value.
  public mutating func clearStreamingFeatures() {self._streamingFeatures = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _config: Google_Cloud_Speech_V2_RecognitionConfig? = nil
  fileprivate var _configMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
  fileprivate var _streamingFeatures: Google_Cloud_Speech_V2_StreamingRecognitionFeatures? = nil
}

/// Request message for the
/// [StreamingRecognize][google.cloud.speech.v2.Speech.StreamingRecognize]
/// method. Multiple
/// [StreamingRecognizeRequest][google.cloud.speech.v2.StreamingRecognizeRequest]
/// messages are sent in one call.
///
/// If the [Recognizer][google.cloud.speech.v2.Recognizer] referenced by
/// [recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer]
/// contains a fully specified request configuration then the stream may only
/// contain messages with only
/// [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.
///
/// Otherwise the first message must contain a
/// [recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer] and
/// a
/// [streaming_config][google.cloud.speech.v2.StreamingRecognizeRequest.streaming_config]
/// message that together fully specify the request configuration and must not
/// contain [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio]. All
/// subsequent messages must only have
/// [audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.
public struct Google_Cloud_Speech_V2_StreamingRecognizeRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to use during recognition. The
  /// expected format is
  /// `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
  /// {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
  public var recognizer: String = String()

  public var streamingRequest: Google_Cloud_Speech_V2_StreamingRecognizeRequest.OneOf_StreamingRequest? = nil

  /// StreamingRecognitionConfig to be used in this recognition attempt.
  /// If provided, it will override the default RecognitionConfig stored in the
  /// Recognizer.
  public var streamingConfig: Google_Cloud_Speech_V2_StreamingRecognitionConfig {
    get {
      if case .streamingConfig(let v)? = streamingRequest {return v}
      return Google_Cloud_Speech_V2_StreamingRecognitionConfig()
    }
    set {streamingRequest = .streamingConfig(newValue)}
  }

  /// Inline audio bytes to be Recognized.
  /// Maximum size for this field is 15 KB per request.
  public var audio: Data {
    get {
      if case .audio(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audio(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_StreamingRequest: Equatable {
    /// StreamingRecognitionConfig to be used in this recognition attempt.
    /// If provided, it will override the default RecognitionConfig stored in the
    /// Recognizer.
    case streamingConfig(Google_Cloud_Speech_V2_StreamingRecognitionConfig)
    /// Inline audio bytes to be Recognized.
    /// Maximum size for this field is 15 KB per request.
    case audio(Data)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognizeRequest.OneOf_StreamingRequest, rhs: Google_Cloud_Speech_V2_StreamingRecognizeRequest.OneOf_StreamingRequest) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.streamingConfig, .streamingConfig): return {
        guard case .streamingConfig(let l) = lhs, case .streamingConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.audio, .audio): return {
        guard case .audio(let l) = lhs, case .audio(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Request message for the
/// [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
/// method.
public struct Google_Cloud_Speech_V2_BatchRecognizeRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the Recognizer to use during recognition. The
  /// expected format is
  /// `projects/{project}/locations/{location}/recognizers/{recognizer}`. The
  /// {recognizer} segment may be set to `_` to use an empty implicit Recognizer.
  public var recognizer: String = String()

  /// Features and audio metadata to use for the Automatic Speech Recognition.
  /// This field in combination with the
  /// [config_mask][google.cloud.speech.v2.BatchRecognizeRequest.config_mask]
  /// field can be used to override parts of the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the Recognizer resource.
  public var config: Google_Cloud_Speech_V2_RecognitionConfig {
    get {return _config ?? Google_Cloud_Speech_V2_RecognitionConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  /// The list of fields in
  /// [config][google.cloud.speech.v2.BatchRecognizeRequest.config] that override
  /// the values in the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the recognizer during this recognition request. If no mask is provided,
  /// all given fields in
  /// [config][google.cloud.speech.v2.BatchRecognizeRequest.config] override the
  /// values in the recognizer for this recognition request. If a mask is
  /// provided, only the fields listed in the mask override the config in the
  /// recognizer for this recognition request. If a wildcard (`*`) is provided,
  /// [config][google.cloud.speech.v2.BatchRecognizeRequest.config] completely
  /// overrides and replaces the config in the recognizer for this recognition
  /// request.
  public var configMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _configMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_configMask = newValue}
  }
  /// Returns true if `configMask` has been explicitly set.
  public var hasConfigMask: Bool {return self._configMask != nil}
  /// Clears the value of `configMask`. Subsequent reads from it will return its default value.
  public mutating func clearConfigMask() {self._configMask = nil}

  /// Audio files with file metadata for ASR.
  /// The maximum number of files allowed to be specified is 5.
  public var files: [Google_Cloud_Speech_V2_BatchRecognizeFileMetadata] = []

  /// Configuration options for where to output the transcripts of each file.
  public var recognitionOutputConfig: Google_Cloud_Speech_V2_RecognitionOutputConfig {
    get {return _recognitionOutputConfig ?? Google_Cloud_Speech_V2_RecognitionOutputConfig()}
    set {_recognitionOutputConfig = newValue}
  }
  /// Returns true if `recognitionOutputConfig` has been explicitly set.
  public var hasRecognitionOutputConfig: Bool {return self._recognitionOutputConfig != nil}
  /// Clears the value of `recognitionOutputConfig`. Subsequent reads from it will return its default value.
  public mutating func clearRecognitionOutputConfig() {self._recognitionOutputConfig = nil}

  /// Processing strategy to use for this request.
  public var processingStrategy: Google_Cloud_Speech_V2_BatchRecognizeRequest.ProcessingStrategy = .unspecified

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Possible processing strategies for batch requests.
  public enum ProcessingStrategy: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Default value for the processing strategy. The request is processed as
    /// soon as its received.
    case unspecified // = 0

    /// If selected, processes the request during lower utilization periods for a
    /// price discount. The request is fulfilled within 24 hours.
    case dynamicBatching // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .dynamicBatching
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .dynamicBatching: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _config: Google_Cloud_Speech_V2_RecognitionConfig? = nil
  fileprivate var _configMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
  fileprivate var _recognitionOutputConfig: Google_Cloud_Speech_V2_RecognitionOutputConfig? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_BatchRecognizeRequest.ProcessingStrategy: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_BatchRecognizeRequest.ProcessingStrategy] = [
    .unspecified,
    .dynamicBatching,
  ]
}

#endif  // swift(>=4.2)

/// Output configurations for Cloud Storage.
public struct Google_Cloud_Speech_V2_GcsOutputConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The Cloud Storage URI prefix with which recognition results will be
  /// written.
  public var uri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Output configurations for inline response.
public struct Google_Cloud_Speech_V2_InlineOutputConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Configuration options for the output(s) of recognition.
public struct Google_Cloud_Speech_V2_RecognitionOutputConfig {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var output: Google_Cloud_Speech_V2_RecognitionOutputConfig.OneOf_Output? = nil

  /// If this message is populated, recognition results are written to the
  /// provided Google Cloud Storage URI.
  public var gcsOutputConfig: Google_Cloud_Speech_V2_GcsOutputConfig {
    get {
      if case .gcsOutputConfig(let v)? = output {return v}
      return Google_Cloud_Speech_V2_GcsOutputConfig()
    }
    set {output = .gcsOutputConfig(newValue)}
  }

  /// If this message is populated, recognition results are provided in the
  /// [BatchRecognizeResponse][google.cloud.speech.v2.BatchRecognizeResponse]
  /// message of the Operation when completed. This is only supported when
  /// calling [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
  /// with just one audio file.
  public var inlineResponseConfig: Google_Cloud_Speech_V2_InlineOutputConfig {
    get {
      if case .inlineResponseConfig(let v)? = output {return v}
      return Google_Cloud_Speech_V2_InlineOutputConfig()
    }
    set {output = .inlineResponseConfig(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_Output: Equatable {
    /// If this message is populated, recognition results are written to the
    /// provided Google Cloud Storage URI.
    case gcsOutputConfig(Google_Cloud_Speech_V2_GcsOutputConfig)
    /// If this message is populated, recognition results are provided in the
    /// [BatchRecognizeResponse][google.cloud.speech.v2.BatchRecognizeResponse]
    /// message of the Operation when completed. This is only supported when
    /// calling [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]
    /// with just one audio file.
    case inlineResponseConfig(Google_Cloud_Speech_V2_InlineOutputConfig)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionOutputConfig.OneOf_Output, rhs: Google_Cloud_Speech_V2_RecognitionOutputConfig.OneOf_Output) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.gcsOutputConfig, .gcsOutputConfig): return {
        guard case .gcsOutputConfig(let l) = lhs, case .gcsOutputConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      case (.inlineResponseConfig, .inlineResponseConfig): return {
        guard case .inlineResponseConfig(let l) = lhs, case .inlineResponseConfig(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Response message for
/// [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize] that is
/// packaged into a longrunning [Operation][google.longrunning.Operation].
public struct Google_Cloud_Speech_V2_BatchRecognizeResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Map from filename to the final result for that file.
  public var results: Dictionary<String,Google_Cloud_Speech_V2_BatchRecognizeFileResult> = [:]

  /// When available, billed audio seconds for the corresponding request.
  public var totalBilledDuration: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _totalBilledDuration ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_totalBilledDuration = newValue}
  }
  /// Returns true if `totalBilledDuration` has been explicitly set.
  public var hasTotalBilledDuration: Bool {return self._totalBilledDuration != nil}
  /// Clears the value of `totalBilledDuration`. Subsequent reads from it will return its default value.
  public mutating func clearTotalBilledDuration() {self._totalBilledDuration = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _totalBilledDuration: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// Output type for Cloud Storage of BatchRecognize transcripts. Though this
/// proto isn't returned in this API anywhere, the Cloud Storage transcripts will
/// be this proto serialized and should be parsed as such.
public struct Google_Cloud_Speech_V2_BatchRecognizeResults {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Sequential list of transcription results corresponding to sequential
  /// portions of audio.
  public var results: [Google_Cloud_Speech_V2_SpeechRecognitionResult] = []

  /// Metadata about the recognition.
  public var metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata {
    get {return _metadata ?? Google_Cloud_Speech_V2_RecognitionResponseMetadata()}
    set {_metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return self._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {self._metadata = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata? = nil
}

/// Final results for a single file.
public struct Google_Cloud_Speech_V2_BatchRecognizeFileResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The Cloud Storage URI to which recognition results were written.
  public var uri: String = String()

  /// Error if one was encountered.
  public var error: Google_Rpc_Status {
    get {return _error ?? Google_Rpc_Status()}
    set {_error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return self._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {self._error = nil}

  public var metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata {
    get {return _metadata ?? Google_Cloud_Speech_V2_RecognitionResponseMetadata()}
    set {_metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return self._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {self._metadata = nil}

  /// The transcript for the audio file. This is populated only when
  /// [InlineOutputConfig][google.cloud.speech.v2.InlineOutputConfig] is set in
  /// the
  /// [RecognitionOutputConfig][[google.cloud.speech.v2.RecognitionOutputConfig].
  public var transcript: Google_Cloud_Speech_V2_BatchRecognizeResults {
    get {return _transcript ?? Google_Cloud_Speech_V2_BatchRecognizeResults()}
    set {_transcript = newValue}
  }
  /// Returns true if `transcript` has been explicitly set.
  public var hasTranscript: Bool {return self._transcript != nil}
  /// Clears the value of `transcript`. Subsequent reads from it will return its default value.
  public mutating func clearTranscript() {self._transcript = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _error: Google_Rpc_Status? = nil
  fileprivate var _metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata? = nil
  fileprivate var _transcript: Google_Cloud_Speech_V2_BatchRecognizeResults? = nil
}

/// Metadata about transcription for a single file (for example, progress
/// percent).
public struct Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// How much of the file has been transcribed so far.
  public var progressPercent: Int32 = 0

  /// Error if one was encountered.
  public var error: Google_Rpc_Status {
    get {return _error ?? Google_Rpc_Status()}
    set {_error = newValue}
  }
  /// Returns true if `error` has been explicitly set.
  public var hasError: Bool {return self._error != nil}
  /// Clears the value of `error`. Subsequent reads from it will return its default value.
  public mutating func clearError() {self._error = nil}

  /// The Cloud Storage URI to which recognition results will be written.
  public var uri: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _error: Google_Rpc_Status? = nil
}

/// Operation metadata for
/// [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize].
public struct Google_Cloud_Speech_V2_BatchRecognizeMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Map from provided filename to the transcription metadata for that file.
  public var transcriptionMetadata: Dictionary<String,Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Metadata about a single file in a batch for BatchRecognize.
public struct Google_Cloud_Speech_V2_BatchRecognizeFileMetadata {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The audio source, which is a Google Cloud Storage URI.
  public var audioSource: Google_Cloud_Speech_V2_BatchRecognizeFileMetadata.OneOf_AudioSource? = nil

  /// Cloud Storage URI for the audio file.
  public var uri: String {
    get {
      if case .uri(let v)? = audioSource {return v}
      return String()
    }
    set {audioSource = .uri(newValue)}
  }

  /// Features and audio metadata to use for the Automatic Speech Recognition.
  /// This field in combination with the
  /// [config_mask][google.cloud.speech.v2.BatchRecognizeFileMetadata.config_mask]
  /// field can be used to override parts of the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the Recognizer resource as well as the
  /// [config][google.cloud.speech.v2.BatchRecognizeRequest.config] at the
  /// request level.
  public var config: Google_Cloud_Speech_V2_RecognitionConfig {
    get {return _config ?? Google_Cloud_Speech_V2_RecognitionConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  /// The list of fields in
  /// [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] that
  /// override the values in the
  /// [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]
  /// of the recognizer during this recognition request. If no mask is provided,
  /// all non-default valued fields in
  /// [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] override
  /// the values in the recognizer for this recognition request. If a mask is
  /// provided, only the fields listed in the mask override the config in the
  /// recognizer for this recognition request. If a wildcard (`*`) is provided,
  /// [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config]
  /// completely overrides and replaces the config in the recognizer for this
  /// recognition request.
  public var configMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _configMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_configMask = newValue}
  }
  /// Returns true if `configMask` has been explicitly set.
  public var hasConfigMask: Bool {return self._configMask != nil}
  /// Clears the value of `configMask`. Subsequent reads from it will return its default value.
  public mutating func clearConfigMask() {self._configMask = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// The audio source, which is a Google Cloud Storage URI.
  public enum OneOf_AudioSource: Equatable {
    /// Cloud Storage URI for the audio file.
    case uri(String)

  #if !swift(>=4.1)
    public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeFileMetadata.OneOf_AudioSource, rhs: Google_Cloud_Speech_V2_BatchRecognizeFileMetadata.OneOf_AudioSource) -> Bool {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch (lhs, rhs) {
      case (.uri, .uri): return {
        guard case .uri(let l) = lhs, case .uri(let r) = rhs else { preconditionFailure() }
        return l == r
      }()
      }
    }
  #endif
  }

  public init() {}

  fileprivate var _config: Google_Cloud_Speech_V2_RecognitionConfig? = nil
  fileprivate var _configMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// A streaming speech recognition result corresponding to a portion of the audio
/// that is currently being processed.
public struct Google_Cloud_Speech_V2_StreamingRecognitionResult {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// May contain one or more recognition hypotheses. These alternatives are
  /// ordered in terms of accuracy, with the top (first) alternative being the
  /// most probable, as ranked by the recognizer.
  public var alternatives: [Google_Cloud_Speech_V2_SpeechRecognitionAlternative] = []

  /// If `false`, this
  /// [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult]
  /// represents an interim result that may change. If `true`, this is the final
  /// time the speech service will return this particular
  /// [StreamingRecognitionResult][google.cloud.speech.v2.StreamingRecognitionResult],
  /// the recognizer will not return any further hypotheses for this portion of
  /// the transcript and corresponding audio.
  public var isFinal: Bool = false

  /// An estimate of the likelihood that the recognizer will not change its guess
  /// about this interim result. Values range from 0.0 (completely unstable)
  /// to 1.0 (completely stable). This field is only provided for interim results
  /// ([is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`).
  /// The default of 0.0 is a sentinel value indicating `stability` was not set.
  public var stability: Float = 0

  /// Time offset of the end of this result relative to the beginning of the
  /// audio.
  public var resultEndOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _resultEndOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_resultEndOffset = newValue}
  }
  /// Returns true if `resultEndOffset` has been explicitly set.
  public var hasResultEndOffset: Bool {return self._resultEndOffset != nil}
  /// Clears the value of `resultEndOffset`. Subsequent reads from it will return its default value.
  public mutating func clearResultEndOffset() {self._resultEndOffset = nil}

  /// For multi-channel audio, this is the channel number corresponding to the
  /// recognized result for the audio from that channel.
  /// For
  /// `audio_channel_count` = `N`, its output values can range from `1` to `N`.
  public var channelTag: Int32 = 0

  /// Output only. The [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
  /// language tag of the language in this result. This language code was
  /// detected to have the most likelihood of being spoken in the audio.
  public var languageCode: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _resultEndOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
}

/// `StreamingRecognizeResponse` is the only message returned to the client by
/// `StreamingRecognize`. A series of zero or more `StreamingRecognizeResponse`
/// messages are streamed back to the client. If there is no recognizable
/// audio then no messages are streamed back to the client.
///
/// Here are some examples of `StreamingRecognizeResponse`s that might
/// be returned while processing audio:
///
/// 1. results { alternatives { transcript: "tube" } stability: 0.01 }
///
/// 2. results { alternatives { transcript: "to be a" } stability: 0.01 }
///
/// 3. results { alternatives { transcript: "to be" } stability: 0.9 }
///    results { alternatives { transcript: " or not to be" } stability: 0.01 }
///
/// 4. results { alternatives { transcript: "to be or not to be"
///                             confidence: 0.92 }
///              alternatives { transcript: "to bee or not to bee" }
///              is_final: true }
///
/// 5. results { alternatives { transcript: " that's" } stability: 0.01 }
///
/// 6. results { alternatives { transcript: " that is" } stability: 0.9 }
///    results { alternatives { transcript: " the question" } stability: 0.01 }
///
/// 7. results { alternatives { transcript: " that is the question"
///                             confidence: 0.98 }
///              alternatives { transcript: " that was the question" }
///              is_final: true }
///
/// Notes:
///
/// - Only two of the above responses #4 and #7 contain final results; they are
///   indicated by `is_final: true`. Concatenating these together generates the
///   full transcript: "to be or not to be that is the question".
///
/// - The others contain interim `results`. #3 and #6 contain two interim
///   `results`: the first portion has a high stability and is less likely to
///   change; the second portion has a low stability and is very likely to
///   change. A UI designer might choose to show only high stability `results`.
///
/// - The specific `stability` and `confidence` values shown above are only for
///   illustrative purposes. Actual values may vary.
///
/// - In each response, only one of these fields will be set:
///     `error`,
///     `speech_event_type`, or
///     one or more (repeated) `results`.
public struct Google_Cloud_Speech_V2_StreamingRecognizeResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// This repeated list contains zero or more results that
  /// correspond to consecutive portions of the audio currently being processed.
  /// It contains zero or one
  /// [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`true`
  /// result (the newly settled portion), followed by zero or more
  /// [is_final][google.cloud.speech.v2.StreamingRecognitionResult.is_final]=`false`
  /// results (the interim results).
  public var results: [Google_Cloud_Speech_V2_StreamingRecognitionResult] = []

  /// Indicates the type of speech event.
  public var speechEventType: Google_Cloud_Speech_V2_StreamingRecognizeResponse.SpeechEventType = .unspecified

  /// Time offset between the beginning of the audio and event emission.
  public var speechEventOffset: SwiftProtobuf.Google_Protobuf_Duration {
    get {return _speechEventOffset ?? SwiftProtobuf.Google_Protobuf_Duration()}
    set {_speechEventOffset = newValue}
  }
  /// Returns true if `speechEventOffset` has been explicitly set.
  public var hasSpeechEventOffset: Bool {return self._speechEventOffset != nil}
  /// Clears the value of `speechEventOffset`. Subsequent reads from it will return its default value.
  public mutating func clearSpeechEventOffset() {self._speechEventOffset = nil}

  /// Metadata about the recognition.
  public var metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata {
    get {return _metadata ?? Google_Cloud_Speech_V2_RecognitionResponseMetadata()}
    set {_metadata = newValue}
  }
  /// Returns true if `metadata` has been explicitly set.
  public var hasMetadata: Bool {return self._metadata != nil}
  /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
  public mutating func clearMetadata() {self._metadata = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Indicates the type of speech event.
  public enum SpeechEventType: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// No speech event specified.
    case unspecified // = 0

    /// This event indicates that the server has detected the end of the user's
    /// speech utterance and expects no additional speech. Therefore, the server
    /// will not process additional audio and will close the gRPC bidirectional
    /// stream. This event is only sent if there was a force cutoff due to
    /// silence being detected early. This event is only available through the
    /// `latest_short` [model][google.cloud.speech.v2.Recognizer.model].
    case endOfSingleUtterance // = 1

    /// This event indicates that the server has detected the beginning of human
    /// voice activity in the stream. This event can be returned multiple times
    /// if speech starts and stops repeatedly throughout the stream. This event
    /// is only sent if `voice_activity_events` is set to true.
    case speechActivityBegin // = 2

    /// This event indicates that the server has detected the end of human voice
    /// activity in the stream. This event can be returned multiple times if
    /// speech starts and stops repeatedly throughout the stream. This event is
    /// only sent if `voice_activity_events` is set to true.
    case speechActivityEnd // = 3
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 1: self = .endOfSingleUtterance
      case 2: self = .speechActivityBegin
      case 3: self = .speechActivityEnd
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .endOfSingleUtterance: return 1
      case .speechActivityBegin: return 2
      case .speechActivityEnd: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}

  fileprivate var _speechEventOffset: SwiftProtobuf.Google_Protobuf_Duration? = nil
  fileprivate var _metadata: Google_Cloud_Speech_V2_RecognitionResponseMetadata? = nil
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_StreamingRecognizeResponse.SpeechEventType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_StreamingRecognizeResponse.SpeechEventType] = [
    .unspecified,
    .endOfSingleUtterance,
    .speechActivityBegin,
    .speechActivityEnd,
  ]
}

#endif  // swift(>=4.2)

/// Message representing the config for the Speech-to-Text API. This includes an
/// optional [KMS key](https://cloud.google.com/kms/docs/resource-hierarchy#keys)
/// with which incoming data will be encrypted.
public struct Google_Cloud_Speech_V2_Config {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The name of the config resource. There is exactly one config
  /// resource per project per location. The expected format is
  /// `projects/{project}/locations/{location}/config`.
  public var name: String = String()

  /// Optional. An optional [KMS key
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) that if
  /// present, will be used to encrypt Speech-to-Text resources at-rest. Updating
  /// this key will not encrypt existing resources using this key; only new
  /// resources will be encrypted using this key. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
  public var kmsKeyName: String = String()

  /// Output only. The most recent time this resource was modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return self._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {self._updateTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

/// Request message for the
/// [GetConfig][google.cloud.speech.v2.Speech.GetConfig] method.
public struct Google_Cloud_Speech_V2_GetConfigRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the config to retrieve. There is exactly one config
  /// resource per project per location. The expected format is
  /// `projects/{project}/locations/{location}/config`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UpdateConfig][google.cloud.speech.v2.Speech.UpdateConfig] method.
public struct Google_Cloud_Speech_V2_UpdateConfigRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The config to update.
  ///
  /// The config's `name` field is used to identify the config to be updated.
  /// The expected format is `projects/{project}/locations/{location}/config`.
  public var config: Google_Cloud_Speech_V2_Config {
    get {return _config ?? Google_Cloud_Speech_V2_Config()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  public var hasConfig: Bool {return self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  public mutating func clearConfig() {self._config = nil}

  /// The list of fields to be updated.
  public var updateMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _updateMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_updateMask = newValue}
  }
  /// Returns true if `updateMask` has been explicitly set.
  public var hasUpdateMask: Bool {return self._updateMask != nil}
  /// Clears the value of `updateMask`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateMask() {self._updateMask = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _config: Google_Cloud_Speech_V2_Config? = nil
  fileprivate var _updateMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// CustomClass for biasing in speech recognition. Used to define a set of words
/// or phrases that represents a common concept or theme likely to appear in your
/// audio, for example a list of passenger ship names.
public struct Google_Cloud_Speech_V2_CustomClass {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The resource name of the CustomClass.
  /// Format:
  /// `projects/{project}/locations/{location}/customClasses/{custom_class}`.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Output only. System-assigned unique identifier for the CustomClass.
  public var uid: String {
    get {return _storage._uid}
    set {_uniqueStorage()._uid = newValue}
  }

  /// User-settable, human-readable name for the CustomClass. Must be 63
  /// characters or less.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// A collection of class items.
  public var items: [Google_Cloud_Speech_V2_CustomClass.ClassItem] {
    get {return _storage._items}
    set {_uniqueStorage()._items = newValue}
  }

  /// Output only. The CustomClass lifecycle state.
  public var state: Google_Cloud_Speech_V2_CustomClass.State {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Output only. Creation time.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. The most recent time this resource was modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. The time at which this resource was requested for deletion.
  public var deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._deleteTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._deleteTime = newValue}
  }
  /// Returns true if `deleteTime` has been explicitly set.
  public var hasDeleteTime: Bool {return _storage._deleteTime != nil}
  /// Clears the value of `deleteTime`. Subsequent reads from it will return its default value.
  public mutating func clearDeleteTime() {_uniqueStorage()._deleteTime = nil}

  /// Output only. The time at which this resource will be purged.
  public var expireTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._expireTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._expireTime = newValue}
  }
  /// Returns true if `expireTime` has been explicitly set.
  public var hasExpireTime: Bool {return _storage._expireTime != nil}
  /// Clears the value of `expireTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpireTime() {_uniqueStorage()._expireTime = nil}

  /// Allows users to store small amounts of arbitrary data.
  /// Both the key and the value must be 63 characters or less each.
  /// At most 100 annotations.
  public var annotations: Dictionary<String,String> {
    get {return _storage._annotations}
    set {_uniqueStorage()._annotations = newValue}
  }

  /// Output only. This checksum is computed by the server based on the value of
  /// other fields. This may be sent on update, undelete, and delete requests to
  /// ensure the client has an up-to-date value before proceeding.
  public var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. Whether or not this CustomClass is in the process of being
  /// updated.
  public var reconciling: Bool {
    get {return _storage._reconciling}
    set {_uniqueStorage()._reconciling = newValue}
  }

  /// Output only. The [KMS key
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
  /// the CustomClass is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
  public var kmsKeyName: String {
    get {return _storage._kmsKeyName}
    set {_uniqueStorage()._kmsKeyName = newValue}
  }

  /// Output only. The [KMS key version
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
  /// with which the CustomClass is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
  public var kmsKeyVersionName: String {
    get {return _storage._kmsKeyVersionName}
    set {_uniqueStorage()._kmsKeyVersionName = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Set of states that define the lifecycle of a CustomClass.
  public enum State: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Unspecified state.  This is only used/useful for distinguishing
    /// unset values.
    case unspecified // = 0

    /// The normal and active state.
    case active // = 2

    /// This CustomClass has been deleted.
    case deleted // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 2: self = .active
      case 4: self = .deleted
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .active: return 2
      case .deleted: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  /// An item of the class.
  public struct ClassItem {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The class item's value.
    public var value: String = String()

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_CustomClass.State: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_CustomClass.State] = [
    .unspecified,
    .active,
    .deleted,
  ]
}

#endif  // swift(>=4.2)

/// PhraseSet for biasing in speech recognition. A PhraseSet is used to provide
/// "hints" to the speech recognizer to favor specific words and phrases in the
/// results.
public struct Google_Cloud_Speech_V2_PhraseSet {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Output only. The resource name of the PhraseSet.
  /// Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
  public var name: String {
    get {return _storage._name}
    set {_uniqueStorage()._name = newValue}
  }

  /// Output only. System-assigned unique identifier for the PhraseSet.
  public var uid: String {
    get {return _storage._uid}
    set {_uniqueStorage()._uid = newValue}
  }

  /// A list of word and phrases.
  public var phrases: [Google_Cloud_Speech_V2_PhraseSet.Phrase] {
    get {return _storage._phrases}
    set {_uniqueStorage()._phrases = newValue}
  }

  /// Hint Boost. Positive value will increase the probability that a specific
  /// phrase will be recognized over other similar sounding phrases. The higher
  /// the boost, the higher the chance of false positive recognition as well.
  /// Valid `boost` values are between 0 (exclusive) and 20. We recommend using a
  /// binary search approach to finding the optimal value for your use case as
  /// well as adding phrases both with and without boost to your requests.
  public var boost: Float {
    get {return _storage._boost}
    set {_uniqueStorage()._boost = newValue}
  }

  /// User-settable, human-readable name for the PhraseSet. Must be 63
  /// characters or less.
  public var displayName: String {
    get {return _storage._displayName}
    set {_uniqueStorage()._displayName = newValue}
  }

  /// Output only. The PhraseSet lifecycle state.
  public var state: Google_Cloud_Speech_V2_PhraseSet.State {
    get {return _storage._state}
    set {_uniqueStorage()._state = newValue}
  }

  /// Output only. Creation time.
  public var createTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._createTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._createTime = newValue}
  }
  /// Returns true if `createTime` has been explicitly set.
  public var hasCreateTime: Bool {return _storage._createTime != nil}
  /// Clears the value of `createTime`. Subsequent reads from it will return its default value.
  public mutating func clearCreateTime() {_uniqueStorage()._createTime = nil}

  /// Output only. The most recent time this resource was modified.
  public var updateTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._updateTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._updateTime = newValue}
  }
  /// Returns true if `updateTime` has been explicitly set.
  public var hasUpdateTime: Bool {return _storage._updateTime != nil}
  /// Clears the value of `updateTime`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateTime() {_uniqueStorage()._updateTime = nil}

  /// Output only. The time at which this resource was requested for deletion.
  public var deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._deleteTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._deleteTime = newValue}
  }
  /// Returns true if `deleteTime` has been explicitly set.
  public var hasDeleteTime: Bool {return _storage._deleteTime != nil}
  /// Clears the value of `deleteTime`. Subsequent reads from it will return its default value.
  public mutating func clearDeleteTime() {_uniqueStorage()._deleteTime = nil}

  /// Output only. The time at which this resource will be purged.
  public var expireTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _storage._expireTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_uniqueStorage()._expireTime = newValue}
  }
  /// Returns true if `expireTime` has been explicitly set.
  public var hasExpireTime: Bool {return _storage._expireTime != nil}
  /// Clears the value of `expireTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpireTime() {_uniqueStorage()._expireTime = nil}

  /// Allows users to store small amounts of arbitrary data.
  /// Both the key and the value must be 63 characters or less each.
  /// At most 100 annotations.
  public var annotations: Dictionary<String,String> {
    get {return _storage._annotations}
    set {_uniqueStorage()._annotations = newValue}
  }

  /// Output only. This checksum is computed by the server based on the value of
  /// other fields. This may be sent on update, undelete, and delete requests to
  /// ensure the client has an up-to-date value before proceeding.
  public var etag: String {
    get {return _storage._etag}
    set {_uniqueStorage()._etag = newValue}
  }

  /// Output only. Whether or not this PhraseSet is in the process of being
  /// updated.
  public var reconciling: Bool {
    get {return _storage._reconciling}
    set {_uniqueStorage()._reconciling = newValue}
  }

  /// Output only. The [KMS key
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#keys) with which
  /// the PhraseSet is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}`.
  public var kmsKeyName: String {
    get {return _storage._kmsKeyName}
    set {_uniqueStorage()._kmsKeyName = newValue}
  }

  /// Output only. The [KMS key version
  /// name](https://cloud.google.com/kms/docs/resource-hierarchy#key_versions)
  /// with which the PhraseSet is encrypted. The expected format is
  /// `projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}`.
  public var kmsKeyVersionName: String {
    get {return _storage._kmsKeyVersionName}
    set {_uniqueStorage()._kmsKeyVersionName = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  /// Set of states that define the lifecycle of a PhraseSet.
  public enum State: SwiftProtobuf.Enum {
    public typealias RawValue = Int

    /// Unspecified state.  This is only used/useful for distinguishing
    /// unset values.
    case unspecified // = 0

    /// The normal and active state.
    case active // = 2

    /// This PhraseSet has been deleted.
    case deleted // = 4
    case UNRECOGNIZED(Int)

    public init() {
      self = .unspecified
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unspecified
      case 2: self = .active
      case 4: self = .deleted
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .unspecified: return 0
      case .active: return 2
      case .deleted: return 4
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  /// A Phrase contains words and phrase "hints" so that the speech recognition
  /// is more likely to recognize them. This can be used to improve the accuracy
  /// for specific words and phrases, for example, if specific commands are
  /// typically spoken by the user. This can also be used to add additional words
  /// to the vocabulary of the recognizer.
  ///
  /// List items can also include CustomClass references containing groups of
  /// words that represent common concepts that occur in natural language.
  public struct Phrase {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// The phrase itself.
    public var value: String = String()

    /// Hint Boost. Overrides the boost set at the phrase set level.
    /// Positive value will increase the probability that a specific phrase will
    /// be recognized over other similar sounding phrases. The higher the boost,
    /// the higher the chance of false positive recognition as well. Negative
    /// boost values would correspond to anti-biasing. Anti-biasing is not
    /// enabled, so negative boost values will return an error. Boost values must
    /// be between 0 and 20. Any values outside that range will return an error.
    /// We recommend using a binary search approach to finding the optimal value
    /// for your use case as well as adding phrases both with and without boost
    /// to your requests.
    public var boost: Float = 0

    public var unknownFields = SwiftProtobuf.UnknownStorage()

    public init() {}
  }

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

#if swift(>=4.2)

extension Google_Cloud_Speech_V2_PhraseSet.State: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [Google_Cloud_Speech_V2_PhraseSet.State] = [
    .unspecified,
    .active,
    .deleted,
  ]
}

#endif  // swift(>=4.2)

/// Request message for the
/// [CreateCustomClass][google.cloud.speech.v2.Speech.CreateCustomClass] method.
public struct Google_Cloud_Speech_V2_CreateCustomClassRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The CustomClass to create.
  public var customClass: Google_Cloud_Speech_V2_CustomClass {
    get {return _customClass ?? Google_Cloud_Speech_V2_CustomClass()}
    set {_customClass = newValue}
  }
  /// Returns true if `customClass` has been explicitly set.
  public var hasCustomClass: Bool {return self._customClass != nil}
  /// Clears the value of `customClass`. Subsequent reads from it will return its default value.
  public mutating func clearCustomClass() {self._customClass = nil}

  /// If set, validate the request and preview the CustomClass, but do not
  /// actually create it.
  public var validateOnly: Bool = false

  /// The ID to use for the CustomClass, which will become the final component of
  /// the CustomClass's resource name.
  ///
  /// This value should be 4-63 characters, and valid characters
  /// are /[a-z][0-9]-/.
  public var customClassID: String = String()

  /// Required. The project and location where this CustomClass will be created.
  /// The expected format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _customClass: Google_Cloud_Speech_V2_CustomClass? = nil
}

/// Request message for the
/// [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
public struct Google_Cloud_Speech_V2_ListCustomClassesRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The project and location of CustomClass resources to list. The
  /// expected format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  /// Number of results per requests. A valid page_size ranges from 0 to 100
  /// inclusive. If the page_size is zero or unspecified, a page size of 5 will
  /// be chosen. If the page size exceeds 100, it will be coerced down to 100.
  /// Note that a call might return fewer results than the requested page size.
  public var pageSize: Int32 = 0

  /// A page token, received from a previous
  /// [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] call.
  /// Provide this to retrieve the subsequent page.
  ///
  /// When paginating, all other parameters provided to
  /// [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] must
  /// match the call that provided the page token.
  public var pageToken: String = String()

  /// Whether, or not, to show resources that have been deleted.
  public var showDeleted: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for the
/// [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] method.
public struct Google_Cloud_Speech_V2_ListCustomClassesResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The list of requested CustomClasses.
  public var customClasses: [Google_Cloud_Speech_V2_CustomClass] = []

  /// A token, which can be sent as
  /// [page_token][google.cloud.speech.v2.ListCustomClassesRequest.page_token] to
  /// retrieve the next page. If this field is omitted, there are no subsequent
  /// pages. This token expires after 72 hours.
  public var nextPageToken: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [GetCustomClass][google.cloud.speech.v2.Speech.GetCustomClass] method.
public struct Google_Cloud_Speech_V2_GetCustomClassRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the CustomClass to retrieve. The expected format is
  /// `projects/{project}/locations/{location}/customClasses/{custom_class}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UpdateCustomClass][google.cloud.speech.v2.Speech.UpdateCustomClass] method.
public struct Google_Cloud_Speech_V2_UpdateCustomClassRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The CustomClass to update.
  ///
  /// The CustomClass's `name` field is used to identify the CustomClass to
  /// update. Format:
  /// `projects/{project}/locations/{location}/customClasses/{custom_class}`.
  public var customClass: Google_Cloud_Speech_V2_CustomClass {
    get {return _customClass ?? Google_Cloud_Speech_V2_CustomClass()}
    set {_customClass = newValue}
  }
  /// Returns true if `customClass` has been explicitly set.
  public var hasCustomClass: Bool {return self._customClass != nil}
  /// Clears the value of `customClass`. Subsequent reads from it will return its default value.
  public mutating func clearCustomClass() {self._customClass = nil}

  /// The list of fields to be updated. If empty, all fields are considered for
  /// update.
  public var updateMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _updateMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_updateMask = newValue}
  }
  /// Returns true if `updateMask` has been explicitly set.
  public var hasUpdateMask: Bool {return self._updateMask != nil}
  /// Clears the value of `updateMask`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateMask() {self._updateMask = nil}

  /// If set, validate the request and preview the updated CustomClass, but do
  /// not actually update it.
  public var validateOnly: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _customClass: Google_Cloud_Speech_V2_CustomClass? = nil
  fileprivate var _updateMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// Request message for the
/// [DeleteCustomClass][google.cloud.speech.v2.Speech.DeleteCustomClass] method.
public struct Google_Cloud_Speech_V2_DeleteCustomClassRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the CustomClass to delete.
  /// Format:
  /// `projects/{project}/locations/{location}/customClasses/{custom_class}`
  public var name: String = String()

  /// If set, validate the request and preview the deleted CustomClass, but do
  /// not actually delete it.
  public var validateOnly: Bool = false

  /// If set to true, and the CustomClass is not found, the request will succeed
  /// and  be a no-op (no Operation is recorded in this case).
  public var allowMissing: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UndeleteCustomClass][google.cloud.speech.v2.Speech.UndeleteCustomClass]
/// method.
public struct Google_Cloud_Speech_V2_UndeleteCustomClassRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the CustomClass to undelete.
  /// Format:
  /// `projects/{project}/locations/{location}/customClasses/{custom_class}`
  public var name: String = String()

  /// If set, validate the request and preview the undeleted CustomClass, but do
  /// not actually undelete it.
  public var validateOnly: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [CreatePhraseSet][google.cloud.speech.v2.Speech.CreatePhraseSet] method.
public struct Google_Cloud_Speech_V2_CreatePhraseSetRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The PhraseSet to create.
  public var phraseSet: Google_Cloud_Speech_V2_PhraseSet {
    get {return _phraseSet ?? Google_Cloud_Speech_V2_PhraseSet()}
    set {_phraseSet = newValue}
  }
  /// Returns true if `phraseSet` has been explicitly set.
  public var hasPhraseSet: Bool {return self._phraseSet != nil}
  /// Clears the value of `phraseSet`. Subsequent reads from it will return its default value.
  public mutating func clearPhraseSet() {self._phraseSet = nil}

  /// If set, validate the request and preview the PhraseSet, but do not
  /// actually create it.
  public var validateOnly: Bool = false

  /// The ID to use for the PhraseSet, which will become the final component of
  /// the PhraseSet's resource name.
  ///
  /// This value should be 4-63 characters, and valid characters
  /// are /[a-z][0-9]-/.
  public var phraseSetID: String = String()

  /// Required. The project and location where this PhraseSet will be created.
  /// The expected format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _phraseSet: Google_Cloud_Speech_V2_PhraseSet? = nil
}

/// Request message for the
/// [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
public struct Google_Cloud_Speech_V2_ListPhraseSetsRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The project and location of PhraseSet resources to list. The
  /// expected format is `projects/{project}/locations/{location}`.
  public var parent: String = String()

  /// The maximum number of PhraseSets to return. The service may return fewer
  /// than this value. If unspecified, at most 5 PhraseSets will be returned.
  /// The maximum value is 100; values above 100 will be coerced to 100.
  public var pageSize: Int32 = 0

  /// A page token, received from a previous
  /// [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] call.
  /// Provide this to retrieve the subsequent page.
  ///
  /// When paginating, all other parameters provided to
  /// [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] must match
  /// the call that provided the page token.
  public var pageToken: String = String()

  /// Whether, or not, to show resources that have been deleted.
  public var showDeleted: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Response message for the
/// [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] method.
public struct Google_Cloud_Speech_V2_ListPhraseSetsResponse {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// The list of requested PhraseSets.
  public var phraseSets: [Google_Cloud_Speech_V2_PhraseSet] = []

  /// A token, which can be sent as
  /// [page_token][google.cloud.speech.v2.ListPhraseSetsRequest.page_token] to
  /// retrieve the next page. If this field is omitted, there are no subsequent
  /// pages. This token expires after 72 hours.
  public var nextPageToken: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [GetPhraseSet][google.cloud.speech.v2.Speech.GetPhraseSet] method.
public struct Google_Cloud_Speech_V2_GetPhraseSetRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the PhraseSet to retrieve. The expected format is
  /// `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
  public var name: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UpdatePhraseSet][google.cloud.speech.v2.Speech.UpdatePhraseSet] method.
public struct Google_Cloud_Speech_V2_UpdatePhraseSetRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The PhraseSet to update.
  ///
  /// The PhraseSet's `name` field is used to identify the PhraseSet to update.
  /// Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`.
  public var phraseSet: Google_Cloud_Speech_V2_PhraseSet {
    get {return _phraseSet ?? Google_Cloud_Speech_V2_PhraseSet()}
    set {_phraseSet = newValue}
  }
  /// Returns true if `phraseSet` has been explicitly set.
  public var hasPhraseSet: Bool {return self._phraseSet != nil}
  /// Clears the value of `phraseSet`. Subsequent reads from it will return its default value.
  public mutating func clearPhraseSet() {self._phraseSet = nil}

  /// The list of fields to update. If empty, all non-default valued fields are
  /// considered for update. Use `*` to update the entire PhraseSet resource.
  public var updateMask: SwiftProtobuf.Google_Protobuf_FieldMask {
    get {return _updateMask ?? SwiftProtobuf.Google_Protobuf_FieldMask()}
    set {_updateMask = newValue}
  }
  /// Returns true if `updateMask` has been explicitly set.
  public var hasUpdateMask: Bool {return self._updateMask != nil}
  /// Clears the value of `updateMask`. Subsequent reads from it will return its default value.
  public mutating func clearUpdateMask() {self._updateMask = nil}

  /// If set, validate the request and preview the updated PhraseSet, but do not
  /// actually update it.
  public var validateOnly: Bool = false

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _phraseSet: Google_Cloud_Speech_V2_PhraseSet? = nil
  fileprivate var _updateMask: SwiftProtobuf.Google_Protobuf_FieldMask? = nil
}

/// Request message for the
/// [DeletePhraseSet][google.cloud.speech.v2.Speech.DeletePhraseSet] method.
public struct Google_Cloud_Speech_V2_DeletePhraseSetRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the PhraseSet to delete.
  /// Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
  public var name: String = String()

  /// If set, validate the request and preview the deleted PhraseSet, but do not
  /// actually delete it.
  public var validateOnly: Bool = false

  /// If set to true, and the PhraseSet is not found, the request will succeed
  /// and  be a no-op (no Operation is recorded in this case).
  public var allowMissing: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// Request message for the
/// [UndeletePhraseSet][google.cloud.speech.v2.Speech.UndeletePhraseSet]
/// method.
public struct Google_Cloud_Speech_V2_UndeletePhraseSetRequest {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// Required. The name of the PhraseSet to undelete.
  /// Format: `projects/{project}/locations/{location}/phraseSets/{phrase_set}`
  public var name: String = String()

  /// If set, validate the request and preview the undeleted PhraseSet, but do
  /// not actually undelete it.
  public var validateOnly: Bool = false

  /// This checksum is computed by the server based on the value of other
  /// fields. This may be sent on update, undelete, and delete requests to ensure
  /// the client has an up-to-date value before proceeding.
  public var etag: String = String()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

#if swift(>=5.5) && canImport(_Concurrency)
extension Google_Cloud_Speech_V2_CreateRecognizerRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_OperationMetadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_OperationMetadata.OneOf_Request: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_OperationMetadata.OneOf_Metadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListRecognizersRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListRecognizersResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_GetRecognizerRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UpdateRecognizerRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_DeleteRecognizerRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UndeleteRecognizerRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_Recognizer: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_Recognizer.State: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_AutoDetectDecodingConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ExplicitDecodingConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ExplicitDecodingConfig.AudioEncoding: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeakerDiarizationConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionFeatures: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionFeatures.MultiChannelMode: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeechAdaptation: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet.OneOf_Value: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionConfig.OneOf_DecodingConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognizeRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognizeRequest.OneOf_AudioSource: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionResponseMetadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeechRecognitionAlternative: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_WordInfo: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_SpeechRecognitionResult: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognizeResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognitionFeatures: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognitionConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognizeRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognizeRequest.OneOf_StreamingRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeRequest.ProcessingStrategy: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_GcsOutputConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_InlineOutputConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionOutputConfig: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_RecognitionOutputConfig.OneOf_Output: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeResults: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeFileResult: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeMetadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeFileMetadata: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_BatchRecognizeFileMetadata.OneOf_AudioSource: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognitionResult: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognizeResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_StreamingRecognizeResponse.SpeechEventType: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_Config: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_GetConfigRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UpdateConfigRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_CustomClass: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_CustomClass.State: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_CustomClass.ClassItem: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_PhraseSet: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_PhraseSet.State: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_PhraseSet.Phrase: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_CreateCustomClassRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListCustomClassesRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListCustomClassesResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_GetCustomClassRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UpdateCustomClassRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_DeleteCustomClassRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UndeleteCustomClassRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_CreatePhraseSetRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListPhraseSetsRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_ListPhraseSetsResponse: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_GetPhraseSetRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UpdatePhraseSetRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_DeletePhraseSetRequest: @unchecked Sendable {}
extension Google_Cloud_Speech_V2_UndeletePhraseSetRequest: @unchecked Sendable {}
#endif  // swift(>=5.5) && canImport(_Concurrency)

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.speech.v2"

extension Google_Cloud_Speech_V2_CreateRecognizerRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateRecognizerRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "recognizer"),
    2: .standard(proto: "validate_only"),
    3: .standard(proto: "recognizer_id"),
    4: .same(proto: "parent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._recognizer) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.recognizerID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._recognizer {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.recognizerID.isEmpty {
      try visitor.visitSingularStringField(value: self.recognizerID, fieldNumber: 3)
    }
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_CreateRecognizerRequest, rhs: Google_Cloud_Speech_V2_CreateRecognizerRequest) -> Bool {
    if lhs._recognizer != rhs._recognizer {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.recognizerID != rhs.recognizerID {return false}
    if lhs.parent != rhs.parent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_OperationMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".OperationMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "create_time"),
    2: .standard(proto: "update_time"),
    3: .same(proto: "resource"),
    4: .same(proto: "method"),
    6: .standard(proto: "kms_key_name"),
    7: .standard(proto: "kms_key_version_name"),
    8: .standard(proto: "batch_recognize_request"),
    9: .standard(proto: "create_recognizer_request"),
    10: .standard(proto: "update_recognizer_request"),
    11: .standard(proto: "delete_recognizer_request"),
    12: .standard(proto: "undelete_recognizer_request"),
    13: .standard(proto: "create_custom_class_request"),
    14: .standard(proto: "update_custom_class_request"),
    15: .standard(proto: "delete_custom_class_request"),
    16: .standard(proto: "undelete_custom_class_request"),
    17: .standard(proto: "create_phrase_set_request"),
    18: .standard(proto: "update_phrase_set_request"),
    19: .standard(proto: "delete_phrase_set_request"),
    20: .standard(proto: "undelete_phrase_set_request"),
    21: .standard(proto: "update_config_request"),
    22: .standard(proto: "progress_percent"),
    23: .standard(proto: "batch_recognize_metadata"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._createTime) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._updateTime) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.resource) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.method) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.kmsKeyName) }()
      case 7: try { try decoder.decodeSingularStringField(value: &self.kmsKeyVersionName) }()
      case 8: try {
        var v: Google_Cloud_Speech_V2_BatchRecognizeRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .batchRecognizeRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .batchRecognizeRequest(v)
        }
      }()
      case 9: try {
        var v: Google_Cloud_Speech_V2_CreateRecognizerRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .createRecognizerRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .createRecognizerRequest(v)
        }
      }()
      case 10: try {
        var v: Google_Cloud_Speech_V2_UpdateRecognizerRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .updateRecognizerRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .updateRecognizerRequest(v)
        }
      }()
      case 11: try {
        var v: Google_Cloud_Speech_V2_DeleteRecognizerRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .deleteRecognizerRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .deleteRecognizerRequest(v)
        }
      }()
      case 12: try {
        var v: Google_Cloud_Speech_V2_UndeleteRecognizerRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .undeleteRecognizerRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .undeleteRecognizerRequest(v)
        }
      }()
      case 13: try {
        var v: Google_Cloud_Speech_V2_CreateCustomClassRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .createCustomClassRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .createCustomClassRequest(v)
        }
      }()
      case 14: try {
        var v: Google_Cloud_Speech_V2_UpdateCustomClassRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .updateCustomClassRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .updateCustomClassRequest(v)
        }
      }()
      case 15: try {
        var v: Google_Cloud_Speech_V2_DeleteCustomClassRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .deleteCustomClassRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .deleteCustomClassRequest(v)
        }
      }()
      case 16: try {
        var v: Google_Cloud_Speech_V2_UndeleteCustomClassRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .undeleteCustomClassRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .undeleteCustomClassRequest(v)
        }
      }()
      case 17: try {
        var v: Google_Cloud_Speech_V2_CreatePhraseSetRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .createPhraseSetRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .createPhraseSetRequest(v)
        }
      }()
      case 18: try {
        var v: Google_Cloud_Speech_V2_UpdatePhraseSetRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .updatePhraseSetRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .updatePhraseSetRequest(v)
        }
      }()
      case 19: try {
        var v: Google_Cloud_Speech_V2_DeletePhraseSetRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .deletePhraseSetRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .deletePhraseSetRequest(v)
        }
      }()
      case 20: try {
        var v: Google_Cloud_Speech_V2_UndeletePhraseSetRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .undeletePhraseSetRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .undeletePhraseSetRequest(v)
        }
      }()
      case 21: try {
        var v: Google_Cloud_Speech_V2_UpdateConfigRequest?
        var hadOneofValue = false
        if let current = self.request {
          hadOneofValue = true
          if case .updateConfigRequest(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.request = .updateConfigRequest(v)
        }
      }()
      case 22: try { try decoder.decodeSingularInt32Field(value: &self.progressPercent) }()
      case 23: try {
        var v: Google_Cloud_Speech_V2_BatchRecognizeMetadata?
        var hadOneofValue = false
        if let current = self.metadata {
          hadOneofValue = true
          if case .batchRecognizeMetadata(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.metadata = .batchRecognizeMetadata(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._createTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._updateTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.resource.isEmpty {
      try visitor.visitSingularStringField(value: self.resource, fieldNumber: 3)
    }
    if !self.method.isEmpty {
      try visitor.visitSingularStringField(value: self.method, fieldNumber: 4)
    }
    if !self.kmsKeyName.isEmpty {
      try visitor.visitSingularStringField(value: self.kmsKeyName, fieldNumber: 6)
    }
    if !self.kmsKeyVersionName.isEmpty {
      try visitor.visitSingularStringField(value: self.kmsKeyVersionName, fieldNumber: 7)
    }
    switch self.request {
    case .batchRecognizeRequest?: try {
      guard case .batchRecognizeRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }()
    case .createRecognizerRequest?: try {
      guard case .createRecognizerRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    }()
    case .updateRecognizerRequest?: try {
      guard case .updateRecognizerRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    }()
    case .deleteRecognizerRequest?: try {
      guard case .deleteRecognizerRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
    }()
    case .undeleteRecognizerRequest?: try {
      guard case .undeleteRecognizerRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
    }()
    case .createCustomClassRequest?: try {
      guard case .createCustomClassRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
    }()
    case .updateCustomClassRequest?: try {
      guard case .updateCustomClassRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
    }()
    case .deleteCustomClassRequest?: try {
      guard case .deleteCustomClassRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
    }()
    case .undeleteCustomClassRequest?: try {
      guard case .undeleteCustomClassRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
    }()
    case .createPhraseSetRequest?: try {
      guard case .createPhraseSetRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
    }()
    case .updatePhraseSetRequest?: try {
      guard case .updatePhraseSetRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
    }()
    case .deletePhraseSetRequest?: try {
      guard case .deletePhraseSetRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
    }()
    case .undeletePhraseSetRequest?: try {
      guard case .undeletePhraseSetRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
    }()
    case .updateConfigRequest?: try {
      guard case .updateConfigRequest(let v)? = self.request else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
    }()
    case nil: break
    }
    if self.progressPercent != 0 {
      try visitor.visitSingularInt32Field(value: self.progressPercent, fieldNumber: 22)
    }
    try { if case .batchRecognizeMetadata(let v)? = self.metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_OperationMetadata, rhs: Google_Cloud_Speech_V2_OperationMetadata) -> Bool {
    if lhs._createTime != rhs._createTime {return false}
    if lhs._updateTime != rhs._updateTime {return false}
    if lhs.resource != rhs.resource {return false}
    if lhs.method != rhs.method {return false}
    if lhs.kmsKeyName != rhs.kmsKeyName {return false}
    if lhs.kmsKeyVersionName != rhs.kmsKeyVersionName {return false}
    if lhs.request != rhs.request {return false}
    if lhs.progressPercent != rhs.progressPercent {return false}
    if lhs.metadata != rhs.metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListRecognizersRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListRecognizersRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "page_size"),
    3: .standard(proto: "page_token"),
    4: .standard(proto: "show_deleted"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.pageSize) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.showDeleted) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if self.pageSize != 0 {
      try visitor.visitSingularInt32Field(value: self.pageSize, fieldNumber: 2)
    }
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 3)
    }
    if self.showDeleted != false {
      try visitor.visitSingularBoolField(value: self.showDeleted, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListRecognizersRequest, rhs: Google_Cloud_Speech_V2_ListRecognizersRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.pageSize != rhs.pageSize {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.showDeleted != rhs.showDeleted {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListRecognizersResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListRecognizersResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "recognizers"),
    2: .standard(proto: "next_page_token"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.recognizers) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.recognizers.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.recognizers, fieldNumber: 1)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListRecognizersResponse, rhs: Google_Cloud_Speech_V2_ListRecognizersResponse) -> Bool {
    if lhs.recognizers != rhs.recognizers {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_GetRecognizerRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetRecognizerRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_GetRecognizerRequest, rhs: Google_Cloud_Speech_V2_GetRecognizerRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UpdateRecognizerRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UpdateRecognizerRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "recognizer"),
    2: .standard(proto: "update_mask"),
    4: .standard(proto: "validate_only"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._recognizer) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._updateMask) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._recognizer {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._updateMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UpdateRecognizerRequest, rhs: Google_Cloud_Speech_V2_UpdateRecognizerRequest) -> Bool {
    if lhs._recognizer != rhs._recognizer {return false}
    if lhs._updateMask != rhs._updateMask {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_DeleteRecognizerRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DeleteRecognizerRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "validate_only"),
    4: .standard(proto: "allow_missing"),
    3: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.allowMissing) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 3)
    }
    if self.allowMissing != false {
      try visitor.visitSingularBoolField(value: self.allowMissing, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_DeleteRecognizerRequest, rhs: Google_Cloud_Speech_V2_DeleteRecognizerRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.allowMissing != rhs.allowMissing {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UndeleteRecognizerRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UndeleteRecognizerRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    3: .standard(proto: "validate_only"),
    4: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 3)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UndeleteRecognizerRequest, rhs: Google_Cloud_Speech_V2_UndeleteRecognizerRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_Recognizer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Recognizer"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "uid"),
    3: .standard(proto: "display_name"),
    4: .same(proto: "model"),
    17: .standard(proto: "language_codes"),
    6: .standard(proto: "default_recognition_config"),
    7: .same(proto: "annotations"),
    8: .same(proto: "state"),
    9: .standard(proto: "create_time"),
    10: .standard(proto: "update_time"),
    11: .standard(proto: "delete_time"),
    14: .standard(proto: "expire_time"),
    12: .same(proto: "etag"),
    13: .same(proto: "reconciling"),
    15: .standard(proto: "kms_key_name"),
    16: .standard(proto: "kms_key_version_name"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _uid: String = String()
    var _displayName: String = String()
    var _model: String = String()
    var _languageCodes: [String] = []
    var _defaultRecognitionConfig: Google_Cloud_Speech_V2_RecognitionConfig? = nil
    var _annotations: Dictionary<String,String> = [:]
    var _state: Google_Cloud_Speech_V2_Recognizer.State = .unspecified
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _expireTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _etag: String = String()
    var _reconciling: Bool = false
    var _kmsKeyName: String = String()
    var _kmsKeyVersionName: String = String()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _uid = source._uid
      _displayName = source._displayName
      _model = source._model
      _languageCodes = source._languageCodes
      _defaultRecognitionConfig = source._defaultRecognitionConfig
      _annotations = source._annotations
      _state = source._state
      _createTime = source._createTime
      _updateTime = source._updateTime
      _deleteTime = source._deleteTime
      _expireTime = source._expireTime
      _etag = source._etag
      _reconciling = source._reconciling
      _kmsKeyName = source._kmsKeyName
      _kmsKeyVersionName = source._kmsKeyVersionName
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._uid) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._model) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._defaultRecognitionConfig) }()
        case 7: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._annotations) }()
        case 8: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 10: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 11: try { try decoder.decodeSingularMessageField(value: &_storage._deleteTime) }()
        case 12: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 13: try { try decoder.decodeSingularBoolField(value: &_storage._reconciling) }()
        case 14: try { try decoder.decodeSingularMessageField(value: &_storage._expireTime) }()
        case 15: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyName) }()
        case 16: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyVersionName) }()
        case 17: try { try decoder.decodeRepeatedStringField(value: &_storage._languageCodes) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._uid.isEmpty {
        try visitor.visitSingularStringField(value: _storage._uid, fieldNumber: 2)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 3)
      }
      if !_storage._model.isEmpty {
        try visitor.visitSingularStringField(value: _storage._model, fieldNumber: 4)
      }
      try { if let v = _storage._defaultRecognitionConfig {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      if !_storage._annotations.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._annotations, fieldNumber: 7)
      }
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 8)
      }
      try { if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      try { if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      } }()
      try { if let v = _storage._deleteTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      } }()
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 12)
      }
      if _storage._reconciling != false {
        try visitor.visitSingularBoolField(value: _storage._reconciling, fieldNumber: 13)
      }
      try { if let v = _storage._expireTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      } }()
      if !_storage._kmsKeyName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyName, fieldNumber: 15)
      }
      if !_storage._kmsKeyVersionName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyVersionName, fieldNumber: 16)
      }
      if !_storage._languageCodes.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._languageCodes, fieldNumber: 17)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_Recognizer, rhs: Google_Cloud_Speech_V2_Recognizer) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._uid != rhs_storage._uid {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._model != rhs_storage._model {return false}
        if _storage._languageCodes != rhs_storage._languageCodes {return false}
        if _storage._defaultRecognitionConfig != rhs_storage._defaultRecognitionConfig {return false}
        if _storage._annotations != rhs_storage._annotations {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._deleteTime != rhs_storage._deleteTime {return false}
        if _storage._expireTime != rhs_storage._expireTime {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._reconciling != rhs_storage._reconciling {return false}
        if _storage._kmsKeyName != rhs_storage._kmsKeyName {return false}
        if _storage._kmsKeyVersionName != rhs_storage._kmsKeyVersionName {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_Recognizer.State: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STATE_UNSPECIFIED"),
    2: .same(proto: "ACTIVE"),
    4: .same(proto: "DELETED"),
  ]
}

extension Google_Cloud_Speech_V2_AutoDetectDecodingConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AutoDetectDecodingConfig"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_AutoDetectDecodingConfig, rhs: Google_Cloud_Speech_V2_AutoDetectDecodingConfig) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ExplicitDecodingConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ExplicitDecodingConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "encoding"),
    2: .standard(proto: "sample_rate_hertz"),
    3: .standard(proto: "audio_channel_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.encoding) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.sampleRateHertz) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.audioChannelCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.encoding != .unspecified {
      try visitor.visitSingularEnumField(value: self.encoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if self.audioChannelCount != 0 {
      try visitor.visitSingularInt32Field(value: self.audioChannelCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ExplicitDecodingConfig, rhs: Google_Cloud_Speech_V2_ExplicitDecodingConfig) -> Bool {
    if lhs.encoding != rhs.encoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.audioChannelCount != rhs.audioChannelCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ExplicitDecodingConfig.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "AUDIO_ENCODING_UNSPECIFIED"),
    1: .same(proto: "LINEAR16"),
    2: .same(proto: "MULAW"),
    3: .same(proto: "ALAW"),
  ]
}

extension Google_Cloud_Speech_V2_SpeakerDiarizationConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeakerDiarizationConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    2: .standard(proto: "min_speaker_count"),
    3: .standard(proto: "max_speaker_count"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.minSpeakerCount) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self.maxSpeakerCount) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.minSpeakerCount != 0 {
      try visitor.visitSingularInt32Field(value: self.minSpeakerCount, fieldNumber: 2)
    }
    if self.maxSpeakerCount != 0 {
      try visitor.visitSingularInt32Field(value: self.maxSpeakerCount, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_SpeakerDiarizationConfig, rhs: Google_Cloud_Speech_V2_SpeakerDiarizationConfig) -> Bool {
    if lhs.minSpeakerCount != rhs.minSpeakerCount {return false}
    if lhs.maxSpeakerCount != rhs.maxSpeakerCount {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognitionFeatures: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionFeatures"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "profanity_filter"),
    2: .standard(proto: "enable_word_time_offsets"),
    3: .standard(proto: "enable_word_confidence"),
    4: .standard(proto: "enable_automatic_punctuation"),
    14: .standard(proto: "enable_spoken_punctuation"),
    15: .standard(proto: "enable_spoken_emojis"),
    17: .standard(proto: "multi_channel_mode"),
    9: .standard(proto: "diarization_config"),
    16: .standard(proto: "max_alternatives"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.profanityFilter) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.enableWordTimeOffsets) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.enableWordConfidence) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.enableAutomaticPunctuation) }()
      case 9: try { try decoder.decodeSingularMessageField(value: &self._diarizationConfig) }()
      case 14: try { try decoder.decodeSingularBoolField(value: &self.enableSpokenPunctuation) }()
      case 15: try { try decoder.decodeSingularBoolField(value: &self.enableSpokenEmojis) }()
      case 16: try { try decoder.decodeSingularInt32Field(value: &self.maxAlternatives) }()
      case 17: try { try decoder.decodeSingularEnumField(value: &self.multiChannelMode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.profanityFilter != false {
      try visitor.visitSingularBoolField(value: self.profanityFilter, fieldNumber: 1)
    }
    if self.enableWordTimeOffsets != false {
      try visitor.visitSingularBoolField(value: self.enableWordTimeOffsets, fieldNumber: 2)
    }
    if self.enableWordConfidence != false {
      try visitor.visitSingularBoolField(value: self.enableWordConfidence, fieldNumber: 3)
    }
    if self.enableAutomaticPunctuation != false {
      try visitor.visitSingularBoolField(value: self.enableAutomaticPunctuation, fieldNumber: 4)
    }
    try { if let v = self._diarizationConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    } }()
    if self.enableSpokenPunctuation != false {
      try visitor.visitSingularBoolField(value: self.enableSpokenPunctuation, fieldNumber: 14)
    }
    if self.enableSpokenEmojis != false {
      try visitor.visitSingularBoolField(value: self.enableSpokenEmojis, fieldNumber: 15)
    }
    if self.maxAlternatives != 0 {
      try visitor.visitSingularInt32Field(value: self.maxAlternatives, fieldNumber: 16)
    }
    if self.multiChannelMode != .unspecified {
      try visitor.visitSingularEnumField(value: self.multiChannelMode, fieldNumber: 17)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionFeatures, rhs: Google_Cloud_Speech_V2_RecognitionFeatures) -> Bool {
    if lhs.profanityFilter != rhs.profanityFilter {return false}
    if lhs.enableWordTimeOffsets != rhs.enableWordTimeOffsets {return false}
    if lhs.enableWordConfidence != rhs.enableWordConfidence {return false}
    if lhs.enableAutomaticPunctuation != rhs.enableAutomaticPunctuation {return false}
    if lhs.enableSpokenPunctuation != rhs.enableSpokenPunctuation {return false}
    if lhs.enableSpokenEmojis != rhs.enableSpokenEmojis {return false}
    if lhs.multiChannelMode != rhs.multiChannelMode {return false}
    if lhs._diarizationConfig != rhs._diarizationConfig {return false}
    if lhs.maxAlternatives != rhs.maxAlternatives {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognitionFeatures.MultiChannelMode: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "MULTI_CHANNEL_MODE_UNSPECIFIED"),
    1: .same(proto: "SEPARATE_RECOGNITION_PER_CHANNEL"),
  ]
}

extension Google_Cloud_Speech_V2_SpeechAdaptation: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechAdaptation"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "phrase_sets"),
    2: .standard(proto: "custom_classes"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.phraseSets) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.customClasses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.phraseSets.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.phraseSets, fieldNumber: 1)
    }
    if !self.customClasses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.customClasses, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_SpeechAdaptation, rhs: Google_Cloud_Speech_V2_SpeechAdaptation) -> Bool {
    if lhs.phraseSets != rhs.phraseSets {return false}
    if lhs.customClasses != rhs.customClasses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Speech_V2_SpeechAdaptation.protoMessageName + ".AdaptationPhraseSet"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "phrase_set"),
    2: .standard(proto: "inline_phrase_set"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.value != nil {try decoder.handleConflictingOneOf()}
          self.value = .phraseSet(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Speech_V2_PhraseSet?
        var hadOneofValue = false
        if let current = self.value {
          hadOneofValue = true
          if case .inlinePhraseSet(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.value = .inlinePhraseSet(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.value {
    case .phraseSet?: try {
      guard case .phraseSet(let v)? = self.value else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    }()
    case .inlinePhraseSet?: try {
      guard case .inlinePhraseSet(let v)? = self.value else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet, rhs: Google_Cloud_Speech_V2_SpeechAdaptation.AdaptationPhraseSet) -> Bool {
    if lhs.value != rhs.value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    7: .standard(proto: "auto_decoding_config"),
    8: .standard(proto: "explicit_decoding_config"),
    9: .same(proto: "model"),
    10: .standard(proto: "language_codes"),
    2: .same(proto: "features"),
    6: .same(proto: "adaptation"),
  ]

  fileprivate class _StorageClass {
    var _decodingConfig: Google_Cloud_Speech_V2_RecognitionConfig.OneOf_DecodingConfig?
    var _model: String = String()
    var _languageCodes: [String] = []
    var _features: Google_Cloud_Speech_V2_RecognitionFeatures? = nil
    var _adaptation: Google_Cloud_Speech_V2_SpeechAdaptation? = nil

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _decodingConfig = source._decodingConfig
      _model = source._model
      _languageCodes = source._languageCodes
      _features = source._features
      _adaptation = source._adaptation
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._features) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._adaptation) }()
        case 7: try {
          var v: Google_Cloud_Speech_V2_AutoDetectDecodingConfig?
          var hadOneofValue = false
          if let current = _storage._decodingConfig {
            hadOneofValue = true
            if case .autoDecodingConfig(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._decodingConfig = .autoDecodingConfig(v)
          }
        }()
        case 8: try {
          var v: Google_Cloud_Speech_V2_ExplicitDecodingConfig?
          var hadOneofValue = false
          if let current = _storage._decodingConfig {
            hadOneofValue = true
            if case .explicitDecodingConfig(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._decodingConfig = .explicitDecodingConfig(v)
          }
        }()
        case 9: try { try decoder.decodeSingularStringField(value: &_storage._model) }()
        case 10: try { try decoder.decodeRepeatedStringField(value: &_storage._languageCodes) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._features {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._adaptation {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      switch _storage._decodingConfig {
      case .autoDecodingConfig?: try {
        guard case .autoDecodingConfig(let v)? = _storage._decodingConfig else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }()
      case .explicitDecodingConfig?: try {
        guard case .explicitDecodingConfig(let v)? = _storage._decodingConfig else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }()
      case nil: break
      }
      if !_storage._model.isEmpty {
        try visitor.visitSingularStringField(value: _storage._model, fieldNumber: 9)
      }
      if !_storage._languageCodes.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._languageCodes, fieldNumber: 10)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionConfig, rhs: Google_Cloud_Speech_V2_RecognitionConfig) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._decodingConfig != rhs_storage._decodingConfig {return false}
        if _storage._model != rhs_storage._model {return false}
        if _storage._languageCodes != rhs_storage._languageCodes {return false}
        if _storage._features != rhs_storage._features {return false}
        if _storage._adaptation != rhs_storage._adaptation {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognizeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognizeRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .same(proto: "recognizer"),
    1: .same(proto: "config"),
    8: .standard(proto: "config_mask"),
    5: .same(proto: "content"),
    6: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.recognizer) }()
      case 5: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.audioSource != nil {try decoder.handleConflictingOneOf()}
          self.audioSource = .content(v)
        }
      }()
      case 6: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.audioSource != nil {try decoder.handleConflictingOneOf()}
          self.audioSource = .uri(v)
        }
      }()
      case 8: try { try decoder.decodeSingularMessageField(value: &self._configMask) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.recognizer.isEmpty {
      try visitor.visitSingularStringField(value: self.recognizer, fieldNumber: 3)
    }
    switch self.audioSource {
    case .content?: try {
      guard case .content(let v)? = self.audioSource else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 5)
    }()
    case .uri?: try {
      guard case .uri(let v)? = self.audioSource else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    try { if let v = self._configMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognizeRequest, rhs: Google_Cloud_Speech_V2_RecognizeRequest) -> Bool {
    if lhs.recognizer != rhs.recognizer {return false}
    if lhs._config != rhs._config {return false}
    if lhs._configMask != rhs._configMask {return false}
    if lhs.audioSource != rhs.audioSource {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognitionResponseMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionResponseMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    6: .standard(proto: "total_billed_duration"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 6: try { try decoder.decodeSingularMessageField(value: &self._totalBilledDuration) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._totalBilledDuration {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionResponseMetadata, rhs: Google_Cloud_Speech_V2_RecognitionResponseMetadata) -> Bool {
    if lhs._totalBilledDuration != rhs._totalBilledDuration {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_SpeechRecognitionAlternative: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionAlternative"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "transcript"),
    2: .same(proto: "confidence"),
    3: .same(proto: "words"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transcript) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.words) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transcript.isEmpty {
      try visitor.visitSingularStringField(value: self.transcript, fieldNumber: 1)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 2)
    }
    if !self.words.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.words, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_SpeechRecognitionAlternative, rhs: Google_Cloud_Speech_V2_SpeechRecognitionAlternative) -> Bool {
    if lhs.transcript != rhs.transcript {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.words != rhs.words {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_WordInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".WordInfo"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "start_offset"),
    2: .standard(proto: "end_offset"),
    3: .same(proto: "word"),
    4: .same(proto: "confidence"),
    6: .standard(proto: "speaker_label"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._startOffset) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._endOffset) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.word) }()
      case 4: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.speakerLabel) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._startOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._endOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.word.isEmpty {
      try visitor.visitSingularStringField(value: self.word, fieldNumber: 3)
    }
    if self.confidence != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 4)
    }
    if !self.speakerLabel.isEmpty {
      try visitor.visitSingularStringField(value: self.speakerLabel, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_WordInfo, rhs: Google_Cloud_Speech_V2_WordInfo) -> Bool {
    if lhs._startOffset != rhs._startOffset {return false}
    if lhs._endOffset != rhs._endOffset {return false}
    if lhs.word != rhs.word {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.speakerLabel != rhs.speakerLabel {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_SpeechRecognitionResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "alternatives"),
    2: .standard(proto: "channel_tag"),
    4: .standard(proto: "result_end_offset"),
    5: .standard(proto: "language_code"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.alternatives) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.channelTag) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._resultEndOffset) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if self.channelTag != 0 {
      try visitor.visitSingularInt32Field(value: self.channelTag, fieldNumber: 2)
    }
    try { if let v = self._resultEndOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_SpeechRecognitionResult, rhs: Google_Cloud_Speech_V2_SpeechRecognitionResult) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.channelTag != rhs.channelTag {return false}
    if lhs._resultEndOffset != rhs._resultEndOffset {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognizeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognizeResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .same(proto: "results"),
    2: .same(proto: "metadata"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.results) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.results.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.results, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognizeResponse, rhs: Google_Cloud_Speech_V2_RecognizeResponse) -> Bool {
    if lhs.results != rhs.results {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognitionFeatures: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionFeatures"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "enable_voice_activity_events"),
    2: .standard(proto: "interim_results"),
    3: .standard(proto: "voice_activity_timeout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBoolField(value: &self.enableVoiceActivityEvents) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.interimResults) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._voiceActivityTimeout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.enableVoiceActivityEvents != false {
      try visitor.visitSingularBoolField(value: self.enableVoiceActivityEvents, fieldNumber: 1)
    }
    if self.interimResults != false {
      try visitor.visitSingularBoolField(value: self.interimResults, fieldNumber: 2)
    }
    try { if let v = self._voiceActivityTimeout {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognitionFeatures, rhs: Google_Cloud_Speech_V2_StreamingRecognitionFeatures) -> Bool {
    if lhs.enableVoiceActivityEvents != rhs.enableVoiceActivityEvents {return false}
    if lhs.interimResults != rhs.interimResults {return false}
    if lhs._voiceActivityTimeout != rhs._voiceActivityTimeout {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Speech_V2_StreamingRecognitionFeatures.protoMessageName + ".VoiceActivityTimeout"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "speech_start_timeout"),
    2: .standard(proto: "speech_end_timeout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._speechStartTimeout) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._speechEndTimeout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._speechStartTimeout {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._speechEndTimeout {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout, rhs: Google_Cloud_Speech_V2_StreamingRecognitionFeatures.VoiceActivityTimeout) -> Bool {
    if lhs._speechStartTimeout != rhs._speechStartTimeout {return false}
    if lhs._speechEndTimeout != rhs._speechEndTimeout {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    3: .standard(proto: "config_mask"),
    2: .standard(proto: "streaming_features"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._streamingFeatures) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._configMask) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._streamingFeatures {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._configMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognitionConfig, rhs: Google_Cloud_Speech_V2_StreamingRecognitionConfig) -> Bool {
    if lhs._config != rhs._config {return false}
    if lhs._configMask != rhs._configMask {return false}
    if lhs._streamingFeatures != rhs._streamingFeatures {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognizeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognizeRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    3: .same(proto: "recognizer"),
    6: .standard(proto: "streaming_config"),
    5: .same(proto: "audio"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 3: try { try decoder.decodeSingularStringField(value: &self.recognizer) }()
      case 5: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audio(v)
        }
      }()
      case 6: try {
        var v: Google_Cloud_Speech_V2_StreamingRecognitionConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .streamingConfig(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .streamingConfig(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.recognizer.isEmpty {
      try visitor.visitSingularStringField(value: self.recognizer, fieldNumber: 3)
    }
    switch self.streamingRequest {
    case .audio?: try {
      guard case .audio(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 5)
    }()
    case .streamingConfig?: try {
      guard case .streamingConfig(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognizeRequest, rhs: Google_Cloud_Speech_V2_StreamingRecognizeRequest) -> Bool {
    if lhs.recognizer != rhs.recognizer {return false}
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "recognizer"),
    4: .same(proto: "config"),
    5: .standard(proto: "config_mask"),
    3: .same(proto: "files"),
    6: .standard(proto: "recognition_output_config"),
    7: .standard(proto: "processing_strategy"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.recognizer) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.files) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._configMask) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._recognitionOutputConfig) }()
      case 7: try { try decoder.decodeSingularEnumField(value: &self.processingStrategy) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.recognizer.isEmpty {
      try visitor.visitSingularStringField(value: self.recognizer, fieldNumber: 1)
    }
    if !self.files.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.files, fieldNumber: 3)
    }
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._configMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try { if let v = self._recognitionOutputConfig {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    if self.processingStrategy != .unspecified {
      try visitor.visitSingularEnumField(value: self.processingStrategy, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeRequest, rhs: Google_Cloud_Speech_V2_BatchRecognizeRequest) -> Bool {
    if lhs.recognizer != rhs.recognizer {return false}
    if lhs._config != rhs._config {return false}
    if lhs._configMask != rhs._configMask {return false}
    if lhs.files != rhs.files {return false}
    if lhs._recognitionOutputConfig != rhs._recognitionOutputConfig {return false}
    if lhs.processingStrategy != rhs.processingStrategy {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeRequest.ProcessingStrategy: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "PROCESSING_STRATEGY_UNSPECIFIED"),
    1: .same(proto: "DYNAMIC_BATCHING"),
  ]
}

extension Google_Cloud_Speech_V2_GcsOutputConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GcsOutputConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_GcsOutputConfig, rhs: Google_Cloud_Speech_V2_GcsOutputConfig) -> Bool {
    if lhs.uri != rhs.uri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_InlineOutputConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".InlineOutputConfig"
  public static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let _ = try decoder.nextFieldNumber() {
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_InlineOutputConfig, rhs: Google_Cloud_Speech_V2_InlineOutputConfig) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_RecognitionOutputConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".RecognitionOutputConfig"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "gcs_output_config"),
    2: .standard(proto: "inline_response_config"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Google_Cloud_Speech_V2_GcsOutputConfig?
        var hadOneofValue = false
        if let current = self.output {
          hadOneofValue = true
          if case .gcsOutputConfig(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.output = .gcsOutputConfig(v)
        }
      }()
      case 2: try {
        var v: Google_Cloud_Speech_V2_InlineOutputConfig?
        var hadOneofValue = false
        if let current = self.output {
          hadOneofValue = true
          if case .inlineResponseConfig(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.output = .inlineResponseConfig(v)
        }
      }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.output {
    case .gcsOutputConfig?: try {
      guard case .gcsOutputConfig(let v)? = self.output else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .inlineResponseConfig?: try {
      guard case .inlineResponseConfig(let v)? = self.output else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_RecognitionOutputConfig, rhs: Google_Cloud_Speech_V2_RecognitionOutputConfig) -> Bool {
    if lhs.output != rhs.output {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "results"),
    2: .standard(proto: "total_billed_duration"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Google_Cloud_Speech_V2_BatchRecognizeFileResult>.self, value: &self.results) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._totalBilledDuration) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.results.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Google_Cloud_Speech_V2_BatchRecognizeFileResult>.self, value: self.results, fieldNumber: 1)
    }
    try { if let v = self._totalBilledDuration {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeResponse, rhs: Google_Cloud_Speech_V2_BatchRecognizeResponse) -> Bool {
    if lhs.results != rhs.results {return false}
    if lhs._totalBilledDuration != rhs._totalBilledDuration {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeResults: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeResults"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "results"),
    2: .same(proto: "metadata"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.results) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.results.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.results, fieldNumber: 1)
    }
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeResults, rhs: Google_Cloud_Speech_V2_BatchRecognizeResults) -> Bool {
    if lhs.results != rhs.results {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeFileResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeFileResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
    2: .same(proto: "error"),
    3: .same(proto: "metadata"),
    4: .same(proto: "transcript"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._error) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._transcript) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 1)
    }
    try { if let v = self._error {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._transcript {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeFileResult, rhs: Google_Cloud_Speech_V2_BatchRecognizeFileResult) -> Bool {
    if lhs.uri != rhs.uri {return false}
    if lhs._error != rhs._error {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs._transcript != rhs._transcript {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeTranscriptionMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "progress_percent"),
    2: .same(proto: "error"),
    3: .same(proto: "uri"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.progressPercent) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._error) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.uri) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.progressPercent != 0 {
      try visitor.visitSingularInt32Field(value: self.progressPercent, fieldNumber: 1)
    }
    try { if let v = self._error {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.uri.isEmpty {
      try visitor.visitSingularStringField(value: self.uri, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata, rhs: Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata) -> Bool {
    if lhs.progressPercent != rhs.progressPercent {return false}
    if lhs._error != rhs._error {return false}
    if lhs.uri != rhs.uri {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "transcription_metadata"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata>.self, value: &self.transcriptionMetadata) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transcriptionMetadata.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Google_Cloud_Speech_V2_BatchRecognizeTranscriptionMetadata>.self, value: self.transcriptionMetadata, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeMetadata, rhs: Google_Cloud_Speech_V2_BatchRecognizeMetadata) -> Bool {
    if lhs.transcriptionMetadata != rhs.transcriptionMetadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_BatchRecognizeFileMetadata: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".BatchRecognizeFileMetadata"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "uri"),
    4: .same(proto: "config"),
    5: .standard(proto: "config_mask"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.audioSource != nil {try decoder.handleConflictingOneOf()}
          self.audioSource = .uri(v)
        }
      }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._configMask) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if case .uri(let v)? = self.audioSource {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._configMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_BatchRecognizeFileMetadata, rhs: Google_Cloud_Speech_V2_BatchRecognizeFileMetadata) -> Bool {
    if lhs.audioSource != rhs.audioSource {return false}
    if lhs._config != rhs._config {return false}
    if lhs._configMask != rhs._configMask {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognitionResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "alternatives"),
    2: .standard(proto: "is_final"),
    3: .same(proto: "stability"),
    4: .standard(proto: "result_end_offset"),
    5: .standard(proto: "channel_tag"),
    6: .standard(proto: "language_code"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.alternatives) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isFinal) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.stability) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._resultEndOffset) }()
      case 5: try { try decoder.decodeSingularInt32Field(value: &self.channelTag) }()
      case 6: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if self.isFinal != false {
      try visitor.visitSingularBoolField(value: self.isFinal, fieldNumber: 2)
    }
    if self.stability != 0 {
      try visitor.visitSingularFloatField(value: self.stability, fieldNumber: 3)
    }
    try { if let v = self._resultEndOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if self.channelTag != 0 {
      try visitor.visitSingularInt32Field(value: self.channelTag, fieldNumber: 5)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognitionResult, rhs: Google_Cloud_Speech_V2_StreamingRecognitionResult) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.isFinal != rhs.isFinal {return false}
    if lhs.stability != rhs.stability {return false}
    if lhs._resultEndOffset != rhs._resultEndOffset {return false}
    if lhs.channelTag != rhs.channelTag {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognizeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StreamingRecognizeResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    6: .same(proto: "results"),
    3: .standard(proto: "speech_event_type"),
    7: .standard(proto: "speech_event_offset"),
    5: .same(proto: "metadata"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 3: try { try decoder.decodeSingularEnumField(value: &self.speechEventType) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._metadata) }()
      case 6: try { try decoder.decodeRepeatedMessageField(value: &self.results) }()
      case 7: try { try decoder.decodeSingularMessageField(value: &self._speechEventOffset) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.speechEventType != .unspecified {
      try visitor.visitSingularEnumField(value: self.speechEventType, fieldNumber: 3)
    }
    try { if let v = self._metadata {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.results.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.results, fieldNumber: 6)
    }
    try { if let v = self._speechEventOffset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_StreamingRecognizeResponse, rhs: Google_Cloud_Speech_V2_StreamingRecognizeResponse) -> Bool {
    if lhs.results != rhs.results {return false}
    if lhs.speechEventType != rhs.speechEventType {return false}
    if lhs._speechEventOffset != rhs._speechEventOffset {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_StreamingRecognizeResponse.SpeechEventType: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SPEECH_EVENT_TYPE_UNSPECIFIED"),
    1: .same(proto: "END_OF_SINGLE_UTTERANCE"),
    2: .same(proto: "SPEECH_ACTIVITY_BEGIN"),
    3: .same(proto: "SPEECH_ACTIVITY_END"),
  ]
}

extension Google_Cloud_Speech_V2_Config: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Config"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "kms_key_name"),
    3: .standard(proto: "update_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.kmsKeyName) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._updateTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if !self.kmsKeyName.isEmpty {
      try visitor.visitSingularStringField(value: self.kmsKeyName, fieldNumber: 2)
    }
    try { if let v = self._updateTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_Config, rhs: Google_Cloud_Speech_V2_Config) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.kmsKeyName != rhs.kmsKeyName {return false}
    if lhs._updateTime != rhs._updateTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_GetConfigRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetConfigRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_GetConfigRequest, rhs: Google_Cloud_Speech_V2_GetConfigRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UpdateConfigRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UpdateConfigRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "config"),
    2: .standard(proto: "update_mask"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._updateMask) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._updateMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UpdateConfigRequest, rhs: Google_Cloud_Speech_V2_UpdateConfigRequest) -> Bool {
    if lhs._config != rhs._config {return false}
    if lhs._updateMask != rhs._updateMask {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_CustomClass: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CustomClass"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "uid"),
    4: .standard(proto: "display_name"),
    5: .same(proto: "items"),
    15: .same(proto: "state"),
    6: .standard(proto: "create_time"),
    7: .standard(proto: "update_time"),
    8: .standard(proto: "delete_time"),
    9: .standard(proto: "expire_time"),
    10: .same(proto: "annotations"),
    11: .same(proto: "etag"),
    12: .same(proto: "reconciling"),
    13: .standard(proto: "kms_key_name"),
    14: .standard(proto: "kms_key_version_name"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _uid: String = String()
    var _displayName: String = String()
    var _items: [Google_Cloud_Speech_V2_CustomClass.ClassItem] = []
    var _state: Google_Cloud_Speech_V2_CustomClass.State = .unspecified
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _expireTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _annotations: Dictionary<String,String> = [:]
    var _etag: String = String()
    var _reconciling: Bool = false
    var _kmsKeyName: String = String()
    var _kmsKeyVersionName: String = String()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _uid = source._uid
      _displayName = source._displayName
      _items = source._items
      _state = source._state
      _createTime = source._createTime
      _updateTime = source._updateTime
      _deleteTime = source._deleteTime
      _expireTime = source._expireTime
      _annotations = source._annotations
      _etag = source._etag
      _reconciling = source._reconciling
      _kmsKeyName = source._kmsKeyName
      _kmsKeyVersionName = source._kmsKeyVersionName
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._uid) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 5: try { try decoder.decodeRepeatedMessageField(value: &_storage._items) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._deleteTime) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._expireTime) }()
        case 10: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._annotations) }()
        case 11: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 12: try { try decoder.decodeSingularBoolField(value: &_storage._reconciling) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyName) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyVersionName) }()
        case 15: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._uid.isEmpty {
        try visitor.visitSingularStringField(value: _storage._uid, fieldNumber: 2)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 4)
      }
      if !_storage._items.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._items, fieldNumber: 5)
      }
      try { if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._deleteTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._expireTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      if !_storage._annotations.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._annotations, fieldNumber: 10)
      }
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 11)
      }
      if _storage._reconciling != false {
        try visitor.visitSingularBoolField(value: _storage._reconciling, fieldNumber: 12)
      }
      if !_storage._kmsKeyName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyName, fieldNumber: 13)
      }
      if !_storage._kmsKeyVersionName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyVersionName, fieldNumber: 14)
      }
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 15)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_CustomClass, rhs: Google_Cloud_Speech_V2_CustomClass) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._uid != rhs_storage._uid {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._items != rhs_storage._items {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._deleteTime != rhs_storage._deleteTime {return false}
        if _storage._expireTime != rhs_storage._expireTime {return false}
        if _storage._annotations != rhs_storage._annotations {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._reconciling != rhs_storage._reconciling {return false}
        if _storage._kmsKeyName != rhs_storage._kmsKeyName {return false}
        if _storage._kmsKeyVersionName != rhs_storage._kmsKeyVersionName {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_CustomClass.State: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STATE_UNSPECIFIED"),
    2: .same(proto: "ACTIVE"),
    4: .same(proto: "DELETED"),
  ]
}

extension Google_Cloud_Speech_V2_CustomClass.ClassItem: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Speech_V2_CustomClass.protoMessageName + ".ClassItem"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "value"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.value) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.value.isEmpty {
      try visitor.visitSingularStringField(value: self.value, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_CustomClass.ClassItem, rhs: Google_Cloud_Speech_V2_CustomClass.ClassItem) -> Bool {
    if lhs.value != rhs.value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_PhraseSet: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".PhraseSet"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .same(proto: "uid"),
    3: .same(proto: "phrases"),
    4: .same(proto: "boost"),
    5: .standard(proto: "display_name"),
    15: .same(proto: "state"),
    6: .standard(proto: "create_time"),
    7: .standard(proto: "update_time"),
    8: .standard(proto: "delete_time"),
    9: .standard(proto: "expire_time"),
    10: .same(proto: "annotations"),
    11: .same(proto: "etag"),
    12: .same(proto: "reconciling"),
    13: .standard(proto: "kms_key_name"),
    14: .standard(proto: "kms_key_version_name"),
  ]

  fileprivate class _StorageClass {
    var _name: String = String()
    var _uid: String = String()
    var _phrases: [Google_Cloud_Speech_V2_PhraseSet.Phrase] = []
    var _boost: Float = 0
    var _displayName: String = String()
    var _state: Google_Cloud_Speech_V2_PhraseSet.State = .unspecified
    var _createTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _updateTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _deleteTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _expireTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
    var _annotations: Dictionary<String,String> = [:]
    var _etag: String = String()
    var _reconciling: Bool = false
    var _kmsKeyName: String = String()
    var _kmsKeyVersionName: String = String()

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _name = source._name
      _uid = source._uid
      _phrases = source._phrases
      _boost = source._boost
      _displayName = source._displayName
      _state = source._state
      _createTime = source._createTime
      _updateTime = source._updateTime
      _deleteTime = source._deleteTime
      _expireTime = source._expireTime
      _annotations = source._annotations
      _etag = source._etag
      _reconciling = source._reconciling
      _kmsKeyName = source._kmsKeyName
      _kmsKeyVersionName = source._kmsKeyVersionName
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._name) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._uid) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._phrases) }()
        case 4: try { try decoder.decodeSingularFloatField(value: &_storage._boost) }()
        case 5: try { try decoder.decodeSingularStringField(value: &_storage._displayName) }()
        case 6: try { try decoder.decodeSingularMessageField(value: &_storage._createTime) }()
        case 7: try { try decoder.decodeSingularMessageField(value: &_storage._updateTime) }()
        case 8: try { try decoder.decodeSingularMessageField(value: &_storage._deleteTime) }()
        case 9: try { try decoder.decodeSingularMessageField(value: &_storage._expireTime) }()
        case 10: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &_storage._annotations) }()
        case 11: try { try decoder.decodeSingularStringField(value: &_storage._etag) }()
        case 12: try { try decoder.decodeSingularBoolField(value: &_storage._reconciling) }()
        case 13: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyName) }()
        case 14: try { try decoder.decodeSingularStringField(value: &_storage._kmsKeyVersionName) }()
        case 15: try { try decoder.decodeSingularEnumField(value: &_storage._state) }()
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._name.isEmpty {
        try visitor.visitSingularStringField(value: _storage._name, fieldNumber: 1)
      }
      if !_storage._uid.isEmpty {
        try visitor.visitSingularStringField(value: _storage._uid, fieldNumber: 2)
      }
      if !_storage._phrases.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._phrases, fieldNumber: 3)
      }
      if _storage._boost != 0 {
        try visitor.visitSingularFloatField(value: _storage._boost, fieldNumber: 4)
      }
      if !_storage._displayName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._displayName, fieldNumber: 5)
      }
      try { if let v = _storage._createTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      } }()
      try { if let v = _storage._updateTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      } }()
      try { if let v = _storage._deleteTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      } }()
      try { if let v = _storage._expireTime {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      } }()
      if !_storage._annotations.isEmpty {
        try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: _storage._annotations, fieldNumber: 10)
      }
      if !_storage._etag.isEmpty {
        try visitor.visitSingularStringField(value: _storage._etag, fieldNumber: 11)
      }
      if _storage._reconciling != false {
        try visitor.visitSingularBoolField(value: _storage._reconciling, fieldNumber: 12)
      }
      if !_storage._kmsKeyName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyName, fieldNumber: 13)
      }
      if !_storage._kmsKeyVersionName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._kmsKeyVersionName, fieldNumber: 14)
      }
      if _storage._state != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._state, fieldNumber: 15)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_PhraseSet, rhs: Google_Cloud_Speech_V2_PhraseSet) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._name != rhs_storage._name {return false}
        if _storage._uid != rhs_storage._uid {return false}
        if _storage._phrases != rhs_storage._phrases {return false}
        if _storage._boost != rhs_storage._boost {return false}
        if _storage._displayName != rhs_storage._displayName {return false}
        if _storage._state != rhs_storage._state {return false}
        if _storage._createTime != rhs_storage._createTime {return false}
        if _storage._updateTime != rhs_storage._updateTime {return false}
        if _storage._deleteTime != rhs_storage._deleteTime {return false}
        if _storage._expireTime != rhs_storage._expireTime {return false}
        if _storage._annotations != rhs_storage._annotations {return false}
        if _storage._etag != rhs_storage._etag {return false}
        if _storage._reconciling != rhs_storage._reconciling {return false}
        if _storage._kmsKeyName != rhs_storage._kmsKeyName {return false}
        if _storage._kmsKeyVersionName != rhs_storage._kmsKeyVersionName {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_PhraseSet.State: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "STATE_UNSPECIFIED"),
    2: .same(proto: "ACTIVE"),
    4: .same(proto: "DELETED"),
  ]
}

extension Google_Cloud_Speech_V2_PhraseSet.Phrase: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = Google_Cloud_Speech_V2_PhraseSet.protoMessageName + ".Phrase"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "value"),
    2: .same(proto: "boost"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.value) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.boost) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.value.isEmpty {
      try visitor.visitSingularStringField(value: self.value, fieldNumber: 1)
    }
    if self.boost != 0 {
      try visitor.visitSingularFloatField(value: self.boost, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_PhraseSet.Phrase, rhs: Google_Cloud_Speech_V2_PhraseSet.Phrase) -> Bool {
    if lhs.value != rhs.value {return false}
    if lhs.boost != rhs.boost {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_CreateCustomClassRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreateCustomClassRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "custom_class"),
    2: .standard(proto: "validate_only"),
    3: .standard(proto: "custom_class_id"),
    4: .same(proto: "parent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._customClass) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.customClassID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._customClass {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.customClassID.isEmpty {
      try visitor.visitSingularStringField(value: self.customClassID, fieldNumber: 3)
    }
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_CreateCustomClassRequest, rhs: Google_Cloud_Speech_V2_CreateCustomClassRequest) -> Bool {
    if lhs._customClass != rhs._customClass {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.customClassID != rhs.customClassID {return false}
    if lhs.parent != rhs.parent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListCustomClassesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListCustomClassesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "page_size"),
    3: .standard(proto: "page_token"),
    4: .standard(proto: "show_deleted"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.pageSize) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.showDeleted) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if self.pageSize != 0 {
      try visitor.visitSingularInt32Field(value: self.pageSize, fieldNumber: 2)
    }
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 3)
    }
    if self.showDeleted != false {
      try visitor.visitSingularBoolField(value: self.showDeleted, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListCustomClassesRequest, rhs: Google_Cloud_Speech_V2_ListCustomClassesRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.pageSize != rhs.pageSize {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.showDeleted != rhs.showDeleted {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListCustomClassesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListCustomClassesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "custom_classes"),
    2: .standard(proto: "next_page_token"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.customClasses) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.customClasses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.customClasses, fieldNumber: 1)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListCustomClassesResponse, rhs: Google_Cloud_Speech_V2_ListCustomClassesResponse) -> Bool {
    if lhs.customClasses != rhs.customClasses {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_GetCustomClassRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetCustomClassRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_GetCustomClassRequest, rhs: Google_Cloud_Speech_V2_GetCustomClassRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UpdateCustomClassRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UpdateCustomClassRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "custom_class"),
    2: .standard(proto: "update_mask"),
    4: .standard(proto: "validate_only"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._customClass) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._updateMask) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._customClass {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._updateMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UpdateCustomClassRequest, rhs: Google_Cloud_Speech_V2_UpdateCustomClassRequest) -> Bool {
    if lhs._customClass != rhs._customClass {return false}
    if lhs._updateMask != rhs._updateMask {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_DeleteCustomClassRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DeleteCustomClassRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "validate_only"),
    4: .standard(proto: "allow_missing"),
    3: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.allowMissing) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 3)
    }
    if self.allowMissing != false {
      try visitor.visitSingularBoolField(value: self.allowMissing, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_DeleteCustomClassRequest, rhs: Google_Cloud_Speech_V2_DeleteCustomClassRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.allowMissing != rhs.allowMissing {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UndeleteCustomClassRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UndeleteCustomClassRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    3: .standard(proto: "validate_only"),
    4: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 3)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UndeleteCustomClassRequest, rhs: Google_Cloud_Speech_V2_UndeleteCustomClassRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_CreatePhraseSetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".CreatePhraseSetRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "phrase_set"),
    2: .standard(proto: "validate_only"),
    3: .standard(proto: "phrase_set_id"),
    4: .same(proto: "parent"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._phraseSet) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.phraseSetID) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._phraseSet {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.phraseSetID.isEmpty {
      try visitor.visitSingularStringField(value: self.phraseSetID, fieldNumber: 3)
    }
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_CreatePhraseSetRequest, rhs: Google_Cloud_Speech_V2_CreatePhraseSetRequest) -> Bool {
    if lhs._phraseSet != rhs._phraseSet {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.phraseSetID != rhs.phraseSetID {return false}
    if lhs.parent != rhs.parent {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListPhraseSetsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListPhraseSetsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "parent"),
    2: .standard(proto: "page_size"),
    3: .standard(proto: "page_token"),
    4: .standard(proto: "show_deleted"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parent) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.pageSize) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.pageToken) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.showDeleted) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.parent.isEmpty {
      try visitor.visitSingularStringField(value: self.parent, fieldNumber: 1)
    }
    if self.pageSize != 0 {
      try visitor.visitSingularInt32Field(value: self.pageSize, fieldNumber: 2)
    }
    if !self.pageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.pageToken, fieldNumber: 3)
    }
    if self.showDeleted != false {
      try visitor.visitSingularBoolField(value: self.showDeleted, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListPhraseSetsRequest, rhs: Google_Cloud_Speech_V2_ListPhraseSetsRequest) -> Bool {
    if lhs.parent != rhs.parent {return false}
    if lhs.pageSize != rhs.pageSize {return false}
    if lhs.pageToken != rhs.pageToken {return false}
    if lhs.showDeleted != rhs.showDeleted {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_ListPhraseSetsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ListPhraseSetsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "phrase_sets"),
    2: .standard(proto: "next_page_token"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.phraseSets) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.nextPageToken) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.phraseSets.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.phraseSets, fieldNumber: 1)
    }
    if !self.nextPageToken.isEmpty {
      try visitor.visitSingularStringField(value: self.nextPageToken, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_ListPhraseSetsResponse, rhs: Google_Cloud_Speech_V2_ListPhraseSetsResponse) -> Bool {
    if lhs.phraseSets != rhs.phraseSets {return false}
    if lhs.nextPageToken != rhs.nextPageToken {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_GetPhraseSetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GetPhraseSetRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_GetPhraseSetRequest, rhs: Google_Cloud_Speech_V2_GetPhraseSetRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UpdatePhraseSetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UpdatePhraseSetRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "phrase_set"),
    2: .standard(proto: "update_mask"),
    4: .standard(proto: "validate_only"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._phraseSet) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._updateMask) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._phraseSet {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._updateMask {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UpdatePhraseSetRequest, rhs: Google_Cloud_Speech_V2_UpdatePhraseSetRequest) -> Bool {
    if lhs._phraseSet != rhs._phraseSet {return false}
    if lhs._updateMask != rhs._updateMask {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_DeletePhraseSetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DeletePhraseSetRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    2: .standard(proto: "validate_only"),
    4: .standard(proto: "allow_missing"),
    3: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.allowMissing) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 2)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 3)
    }
    if self.allowMissing != false {
      try visitor.visitSingularBoolField(value: self.allowMissing, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_DeletePhraseSetRequest, rhs: Google_Cloud_Speech_V2_DeletePhraseSetRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.allowMissing != rhs.allowMissing {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Google_Cloud_Speech_V2_UndeletePhraseSetRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UndeletePhraseSetRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "name"),
    3: .standard(proto: "validate_only"),
    4: .same(proto: "etag"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.validateOnly) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.etag) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    if self.validateOnly != false {
      try visitor.visitSingularBoolField(value: self.validateOnly, fieldNumber: 3)
    }
    if !self.etag.isEmpty {
      try visitor.visitSingularStringField(value: self.etag, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Google_Cloud_Speech_V2_UndeletePhraseSetRequest, rhs: Google_Cloud_Speech_V2_UndeletePhraseSetRequest) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs.validateOnly != rhs.validateOnly {return false}
    if lhs.etag != rhs.etag {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
